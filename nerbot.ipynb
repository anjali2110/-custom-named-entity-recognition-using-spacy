{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals, print_function\n",
    "\n",
    "import plac\n",
    "import random\n",
    "from pathlib import Path\n",
    "import spacy\n",
    "from spacy.util import minibatch, compounding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "def convert_dataturks_to_spacy(dataturks_JSON_FilePath):\n",
    "    try:\n",
    "        training_data = []\n",
    "        lines=[]\n",
    "        with open(dataturks_JSON_FilePath, 'r') as f:\n",
    "            lines = f.readlines()\n",
    "\n",
    "        for line in lines:\n",
    "            data = json.loads(line)\n",
    "            text = data['content']\n",
    "            entities = []\n",
    "            for annotation in data['annotation']:\n",
    "                #only a single point in text annotation.\n",
    "                point = annotation['points'][0]\n",
    "                labels = annotation['label']\n",
    "                # handle both list of labels or a single label.\n",
    "                if not isinstance(labels, list):\n",
    "                    labels = [labels]\n",
    "\n",
    "                for label in labels:\n",
    "                    #dataturks indices are both inclusive [start, end] but spacy is not [start, end)\n",
    "                    entities.append((point['start'], point['end'] + 1 ,label))\n",
    "\n",
    "\n",
    "            training_data.append((text, {\"entities\" : entities}))\n",
    "\n",
    "        return training_data\n",
    "    except Exception as e:\n",
    "        logging.exception(\"Unable to process \" + dataturks_JSON_FilePath + \"\\n\" + \"error = \" + str(e))\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DATA = convert_dataturks_to_spacy(\"C:/Users/Anbu/Desktop/resp/final30desc.json\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('1.\\nABOUT:\\nHangar India is looking for a talented Data Scientist, who is responsible for the development of digital creative using industry standard technologies and applications. He/she codes the creative within the guidelines of interactive best practices and with emphasis on maintaining aesthetics.\\nWHAT YOUï¿½LL DO:\\nDeliver impactful analyses of assigned projects with high quality, on-time, and within estimated hours \\nReview data for insights, trends, and makes key observations\\nSolve problems by thinking through approaches to the data or analysis\\nParticipate as a collaborative team member, holding himself/herself and the team accountable for the quality of the output\\nWHAT YOUï¿½VE GOT:\\n5+ Years of applied analytic experience in a marketing or data driven role, working with marketing database solutions\\nSolid understanding of relational & dimensional database models, including ability to break complex processes and methodologies into easy-to-understand explanations for internal clients or team members\\nSolid understanding of all aspects of building & maintaining marketing database systems including ETL, merge/purse, household, transactional data processing, promotional history, campaign reporting, etc. is preferred \\nExperience in some or all of the following areas of marketing analysis techniques or areas: segmentation/clustering; predictive analytics; digital/ web analytics; marketing campaign measurement; business intelligence/ data visualization reporting, and/or market research\\nProficient with SAS/SPSS and/or OLAP or data-mining tools\\nProficient with SQL (to join and merge data)\\nProficient in Excel, Word, and Powerpoint\\nExperience with Tableau, Domo, Qlik or other major BI software preferred \\nExperience with Web Analytics tools like Google Analytics, Adobe Analytics, etc. preferred\\nStrong problem solving skills\\nDemonstrated success in analyzing trends, creating reports, and providing actionable data-driven insights\\nAbility to manage several projects simultaneously and prioritize appropriately, working within tight deadlines\\nStrong interpersonal skills to collaborate with cross-functional teams \\nStrong written and effective communication skills with the ability to communicate findings to different constituents\\nBachelorï¿½s degree; Masterï¿½s preferred',\n",
       "  {'entities': [(2267, 2285, 'Qualification'),\n",
       "    (2248, 2265, 'Qualification'),\n",
       "    (1780, 1795, 'Skills'),\n",
       "    (1762, 1778, 'Skills'),\n",
       "    (1663, 1670, 'Skills'),\n",
       "    (1636, 1646, 'Skills'),\n",
       "    (1626, 1630, 'Skills'),\n",
       "    (1619, 1624, 'Skills'),\n",
       "    (1576, 1579, 'Skills'),\n",
       "    (693, 701, 'Experience'),\n",
       "    (16, 22, 'Location')]}),\n",
       " ('2.\\nZdaly is revolutionizing how the world works by leveraging massive volume of unstructured public data and transforming them into insights using AI and Big Data. Zdaly is funded by the largest Venture Capitalists of US. Our clients are Fortune 500 companies, Tier 1 consulting, and leading Hedge Funds. Learn more at www.zdaly.com.\\nThe Senior Data Scientist will be part of our core Data Science team and work alongside top Data Scientists from US - MIT, Berkeley, Harvard, IIT, Moscow University, and other top universities of the world.\\nIt is a great opportunity for someone with Deep Experience in Data Science, and programming.\\nRequirements (DO NOT APPLY IF YOU DO NOT MEET THESE REQUIREMENTS):\\nMin 3 years of hands on deep experience with Data Science\\nMin 3 years of experience with managing large Datasets of several Terrabytes\\nExperience with complex clustering and Deep Learning\\nUpto speed with the latest advancements in Data Science\\nOutstanding programming experience in R or Python\\nGraduate from a top university',\n",
       "  {'entities': [(995, 1003, 'Qualification'),\n",
       "    (987, 994, 'Skills'),\n",
       "    (932, 944, 'Skills'),\n",
       "    (763, 770, 'Experience'),\n",
       "    (746, 758, 'Skills'),\n",
       "    (705, 712, 'Experience'),\n",
       "    (603, 615, 'Skills'),\n",
       "    (385, 397, 'Skills'),\n",
       "    (154, 162, 'Skills'),\n",
       "    (147, 149, 'Skills')]}),\n",
       " ('ob description\\nAccenture Consulting transforms our clientsï¿½ businesses by using our deep industry knowledge to identify their issues and then leveraging Accentureï¿½s capabilities to deliver innovative tailor-made solutions. Join Accenture Consulting and guide our clientsï¿½including more than 80% of the Fortune 500ï¿½as they transform their organizations to deliver services at the speed and scale the new digital world demands. Youï¿½ll use your deep industry knowledge to design and execute business solutions and youï¿½ll have the opportunity to integrate expertise from across Accentureï¿½strategy consulting digital technology and operationsï¿½as you bring your vision to life.\\nJob Title: Data Scientist\\nJob Overview\\nKey responsibilities:\\nWe are looking for a Data Scientist who will support our product sales leadership and marketing teams with insights gained from analyzing company data. The ideal candidate is adept at using large data sets to find opportunities for product and process optimization and using models to test the effectiveness of different courses of action. They must have strong experience using a variety of data mining or data analysis methods using a variety of data tools building and implementing models using or creating algorithms and creating or running simulations. They must have a proven ability to drive business results with their data-based insights. They must be comfortable working with a wide range of stakeholders and functional teams. The right candidate will have a passion for discovering solutions hidden in large data sets and working with stakeholders to improve business outcomes.\\nResponsibilities for Data Scientist\\nWork with stakeholders throughout the organization to identify opportunities for leveraging company data to drive business solutions.\\nMine and analyze data from company databases to drive optimization and improvement of product development marketing techniques and business strategies.\\nAssess the effectiveness and accuracy of new data sources and data gathering techniques.\\nDevelop custom data models and algorithms to apply to data sets.\\nUse predictive modeling to increase and optimize customer experiences revenue generation ad targeting and other business outcomes.\\nDevelop company A or B testing framework and test model quality.\\nCoordinate with different functional teams to implement models and monitor outcomes.\\nDevelop processes and tools to monitor and analyze model performance and data accuracy.\\nQualifications For Data Scientist\\nStrong problem solving skills with an emphasis on product development.\\nExperience using statistical computer languages .R SAS Python SLQ etc.. to manipulate data and draw insights from large data sets.\\nExperience working with and creating data architectures.\\nKnowledge of a variety of machine learning techniques .clustering decision tree learning artificial neural networks etc.. and their real-world advantages or drawbacks.\\nKnowledge of advanced statistical techniques and concepts .regression properties of distributions statistical tests and proper usage etc.. and experience with applications.\\nExcellent written and verbal communication skills for coordinating across teams.\\nA drive to learn and master new technologies and techniques.\\nWeï¿½re looking for someone with 4-7 years of experience manipulating data sets and building statistical models has a Masterï¿½s or PHD in Statistics Mathematics Computer Science or another quantitative field and is familiar with the following software or tools:\\nCoding knowledge and experience with several languages: C C++ Java\\nJavaScript etc.\\nKnowledge and experience in statistical and data mining techniques: GLM or Regression Random Forest Boosting Trees text mining social network analysis etc.\\nExperience querying databases and using statistical computer languages: R SAS Python SLQ etc.\\nExperience using web services: Redshift S3 Spark DigitalOcean etc.\\nExperience creating and using advanced machine learning algorithms and statistics: regression simulation scenario analysis modeling clustering decision trees neural networks etc.\\nExperience analyzing data from 3rd party providers: Google Analytics Site Catalyst Coremetrics Adwords Crimson Hexagon Facebook Insights etc.\\nExperience with distributed data or computing tools: Map or Reduce Hadoop Hive Spark Gurobi MySQL etc.',\n",
       "  {'entities': [(4133, 4149, 'Skills'),\n",
       "    (3826, 3829, 'Skills'),\n",
       "    (3815, 3818, 'Skills'),\n",
       "    (3370, 3374, 'Qualification'),\n",
       "    (3359, 3365, 'Qualification'),\n",
       "    (3274, 3283, 'Experience'),\n",
       "    (2849, 2875, 'Skills'),\n",
       "    (2634, 2637, 'Skills'),\n",
       "    (2623, 2626, 'Skills')]}),\n",
       " ('4.\\nJob description\\nReference Code- Inf_EXTERNAL_10038992_21\\nRole Designation- Technology Analyst\\nTechnical & Professional requirements- Basic Qualifications- - Experience Range- 3-5 years. At least 2 years of experience and excellent understanding of Machine learning techniques and algorithm such as Neural Networks, Naive Bayes, SVM, Decision Forests, etc.,o NLP, text analytics technologies.,o Common data science toolkits, such as R, Python Data Science Libraries, MatLab, etc. Excellence in at least one of these is highly desirable,o Data visualization tools, such as D3.js, GGplot, etc.,o Query languages such as SQL, Hive.,\\nGood applied statistics skills, such as distributions, statistical testing, regression, etc.,\\nAt least 5 years of hands on experience with more than one programming language (Python / Scala/ Java/SQL),Role and responsibilities- - ,\\nYou will be responsible for delivering high-value next-generation products on aggressive deadlines and will be required to write high-quality, highly optimized/high-performance and maintainable code that your fellow developers love ,\\nYou will be a core member of a team that does whatever it takes to delight customers, take an iterative and result oriented approach to software development. In this position you will provide best-fit architectural solutions for multi-product, multi-project, multi-industry portfolios providing technology consultation and assisting in defining scope and sizing of work ,\\nYou will be the anchor in Proof of Concept developments and support opportunity identification and pursuit processes and evangelize Infosys brand ,\\nYou will collaborate with some of the best talent in the industry to create and implement innovative high quality solutions, lead and participate in sales and pursuits focused on our clients\\' business needs ,\\nYou will be part of a learning culture, where teamwork and collaboration are encouraged, excellence is rewarded, and diversity is respected and valued ,\\nThe role involves high end technology and hence would require you to be proficient in coding as well,Location- Bangalore\\nJob Locations- Bangalore,Bangalore\\nResponsibilites- \"\\nEnsure effective Design, Development & Validation of activities in line with client needs and architectural requirements.,\\nEnsure continual knowledge management.,\\nAdherence to the organizational guidelines and processes\\nSkills- R, Python, Machine Learning\\nCompany Description-Infosys is a leading provider of next generation consulting,technology and outsourcing solutions.We are dedicated to helping organizations, \\nbuild tomorrows enterprise and advance the way the world works Thats why Forbes ranks us 19th among the top 100 most innovative companies. Our employees partner \\nwith clients to transform their business - one conversation; one idea; one insight at a time.While we are at it, some things remain unchanged- the unwavering ethics, \\ntransparency and respect behind everything we do. We will always be a company powered by intellect and driven by values.So, if your passion is to build solutions that\\n really make a difference to enterprises,the community and your world, Infosys is the right place for you.',\n",
       "  {'entities': [(2394, 2410, 'Skills'),\n",
       "    (2386, 2392, 'Skills'),\n",
       "    (2126, 2135, 'Location'),\n",
       "    (2116, 2125, 'Location'),\n",
       "    (2091, 2100, 'Location'),\n",
       "    (828, 831, 'Skills'),\n",
       "    (823, 827, 'Skills'),\n",
       "    (816, 821, 'Skills'),\n",
       "    (807, 813, 'Skills'),\n",
       "    (735, 742, 'Experience'),\n",
       "    (625, 629, 'Skills'),\n",
       "    (620, 623, 'Skills'),\n",
       "    (540, 558, 'Skills'),\n",
       "    (469, 475, 'Skills'),\n",
       "    (445, 457, 'Skills'),\n",
       "    (438, 444, 'Skills'),\n",
       "    (361, 364, 'Skills'),\n",
       "    (251, 267, 'Skills'),\n",
       "    (198, 205, 'Experience'),\n",
       "    (178, 187, 'Experience')]}),\n",
       " (\"Job description\\nAt Micro Focus, everything we do is based on a simple idea: The fastest way to get results is to build on what you have. Our software solutions enable organizations to do just that. Secure and scalable, with analytics built in, they bridge the gap between existing and emerging ITï¿½fast-tracking digital transformations across DevOps, Hybrid IT, Security, and Predictive Analytics. In the race to innovate, Micro Focus customers have the clear advantage.\\nOur Portfolio Spans The Following Areas\\nDevOps | IT Operations| Cloud | Security | Info Governance | Big Data, Machine Learning, & Analytics\\nWe are looking for experienced data scientists with strong advanced analysis and machine learning model development experience. Data scientists will be working with a team of technical experts on the development of a scalable, real time, big data analytics solutions with data visualizations leveraging the latest technologies. The ideal candidate will have a proven track record of solving large, complex big data challenges, and developing machine learning models to address emerging cybersecurity requirements. Responsibilities will include the analysis of the data to uncover the useful and valuable information and finally supporting the engineering team to build the results into the end product.\\nYou will be working with an experienced team of data scientists and technical experts, and be part of the Security, Risk, and Governance (SR&G) solutions Centers of Excellence (COE). This position is responsible for the design, architecture, development, and implementation of emerging Security and Operations use cases, and partner with R&D engineers to productize the same to support go-to-market initiatives.\\nResponsibilities\\nCollaborate with a multi-disciplinary team of engineers and analysts on a wide range of cybersecurity problems.\\nBring analytical rigor and statistical methods to the challenges of measuring quality, improving security products, and understanding the behavior of end-users, computer systems, and network devices.\\nBuild innovative predictive analytics and data science solutions for a myriad of cybersecurity problems.\\nMulti-task and work independently\\nï¿½Think like an adversaryï¿½\\nIdentify and articulate risks and remediation in a relevant and approachable manner with both technical and non-technical audiences.\\nIdentifies data sources, collects, transforms and prepares large amounts of data for analysis. May also develop tools to help the data collection process as needed.\\nUses appropriate methods, tools and algorithms to analyze the data and create an implementation plan from the business problem.\\nValidates the results of the data analysis to avoid errors.\\nInterprets results and identifies value form the analysis to help solve the business problems. Works with the business or customer and provides guidance on risks and limitations.\\nMonitors and continuously improves the data sources, usability and data mining results.\\nEducation And Experience\\nBachelor's or Master's degree in Computer Science, Statistics or similar quantitative field\\n3-5 years of working experience in machine learning and data science projects;\\n2-3 years of experience in working with large scale production data sets\\nGood understanding of the foundations of machine learning methods\\nExceptional coding skills in SQL, and Python or R\\nExcellent communication skills\\nMust Have\\nKnowledge and Skills\\nExperience with deep learning methods, models and frameworks\\nFamiliarity with multiple programming and scripting languages (such as, Java, Javascript, C/C++, Perl, etc.)\\nFamiliarity with data visualization tools\\nExperience with passive and active measurement techniques\\nExperience with applying statistical modeling, machine learning and data mining algorithms to business problems.\\nProfound understanding of big data systems\\nHigh Want\\nBackground in statistics\\nLinux System knowledge as user and administrator\\nExperience with Vertica or other column store databases is a plus\\nExperience in cybersecurity, network data\\nKnowledge of networking concepts and devices (Firewalls, Routers, Switches, and Load Balancers)\\nKnowledge of network and web related protocols (such as, TCP/IP, UDP, IPSEC, HTTP, HTTPS, DNS, SSH, routing protocols)\",\n",
       "  {'entities': [(3829, 3845, 'Skills'),\n",
       "    (3607, 3625, 'Skills'),\n",
       "    (3578, 3582, 'Skills'),\n",
       "    (3571, 3576, 'Skills'),\n",
       "    (3559, 3563, 'Skills'),\n",
       "    (3553, 3557, 'Skills'),\n",
       "    (3436, 3449, 'Skills'),\n",
       "    (3169, 3178, 'Experience'),\n",
       "    (3090, 3099, 'Experience'),\n",
       "    (3012, 3018, 'Qualification'),\n",
       "    (2998, 3006, 'Qualification'),\n",
       "    (883, 901, 'Skills')]}),\n",
       " ('6.\\nJob description\\nJob Code\\nData Scientist\\nKey Responsibilities\\nUnderstand the key end to end analytics of project requirements and scoping the existing & new requirements\\nAssessing the quality & comprehensiveness of data\\nAnalyzing KPIï¿½s of key business functions like sales & marketing and supply chain\\nWork with Data architects to create and evolve dashboard templates\\nSet data standards for enhancing data maturity for analytics\\nData pre-processing, modelling & post-processing of data\\nComfortable with basic statistical principles and apply them with the data sets\\nMachine Learning: Ability to work with algorithms, understand, interpret and devise your own algorithm for the business problem\\nSelection of right algorithms (Regression, Naï¿½ve Bayes and Random Forest)\\nJob Requirements And Skills\\nData modelling Skills: SQL, Python and analytics model building using Machine Learning\\nData visualisation skills: Power BI / Tableau / Qlikview / Cognos\\nBig Data: Spark, Hive\\nETL Domain: Automotive / Non-Automotive (Industrial Manufacturing/Retail/Energy & utilities, Finance)',\n",
       "  {'entities': [(969, 973, 'Skills'),\n",
       "    (962, 967, 'Skills'),\n",
       "    (952, 960, 'Skills'),\n",
       "    (945, 951, 'Skills'),\n",
       "    (934, 942, 'Skills'),\n",
       "    (924, 931, 'Skills'),\n",
       "    (912, 921, 'Skills'),\n",
       "    (886, 904, 'Skills'),\n",
       "    (869, 885, 'Skills'),\n",
       "    (827, 833, 'Skills'),\n",
       "    (822, 825, 'Skills'),\n",
       "    (569, 585, 'Skills')]}),\n",
       " (\"7.\\nJob description\\nData Scientist\\nGuidewireï¿½s Cyence Risk Analytics products help the property & casualty (P&C) industry to model new and evolving risks such as cyber. By combining internet-scale data listening, adaptive machine learning, and insurance risk modeling, Cyence Risk Analytics provides insights that help P&C customers face new risks, take advantage of new opportunities, and develop new products. To learn more about Cyence Risk Analytics, please visit https://www.guidewire.com/products/cyence.\\nWe are seeking a talented Data Scientist , to join our team in Chennai, India to explore and analyze data at scale.\\nRoles & Responsibilities\\nData exploration, analysis and feature extraction\\nUsing machine learning to extract information from our diverse set of features\\nSoftware engineering and designing data pipelines\\nCreating visualizations appropriate for various audience levels\\nWorking together with cyber analysts, data engineers, modelers, and product managers\\nRequired Skills\\nDegree in a quantitative field (e.g. CS, Statistics, Sciences, Engineering, Economics) with 2-4 years of experience as Data Scientist\\nUnderstanding of various ML techniques (e.g. clustering, anomaly detection, NLP), and the trade-offs between them\\nExperience in data analysis, including (a) querying, segmenting and visualizing data to evaluate hypotheses, and (b) communicating impact to both technical and non-technical audiences\\nExperience working different types of datasets (e.g. unstructured, semi-structured, with missing information)\\nStrong coding ability in Python or R, and SQL\\nAbility to think critically and creatively in a dynamic environment, while picking up new tools and domain knowledge along the way\\nA positive attitude, and a growth mindset\\nPreferred Skills\\nUnderstanding of computer network and cybersecurity\\nExperience with Cloud infrastructure (e.g. AWS), and open source data processing frameworks (e.g. Hadoop, Spark, Mongo and Cassandra)\\nGraduate level statistics courses such as Generalized Linear Models, Time-Series Analysis, Statistical Learning, Bayesian Statistics\\nWhy us?\\nCyence is an analytics platform that quantifies the financial impact of cyber risk. Our first market is the insurance industry, where we help our clients understand, assess and manage risks associated with a wide range of cybersecurity events in a data-informed way. Cyence is now a product family within Guidewire Software, but we have retained our startup culture of collaboration.\\nWe are Guidewire Software, and we're perhaps the best company to work for that you've never heard of. We are proud to be voted a ï¿½Top 3ï¿½ employer on Glassdoor by our own employees, and positioned as a market leader by industry experts like Gartner.  \\nWe serve the second-largest financial services industry in the world (after banking), worth $2 trillion USD. We build the core applications that companies use to sell insurance policies, settle claims, and bill their customers. We also have a portfolio of products serving the innovative needs of our customers in areas such as data management, digital online portals, and predictive analytics.  \\nWe serve customers all over the world, helping them handle billions of dollars of business. This is a lucrative and underserved market, and we have grown rapidly through a combination of quality products, excellent service, innovative technology, and a passionate belief in our core values of rationality, collegiality & integrity.\\n8.\",\n",
       "  {'entities': [(1959, 1967, 'Qualification'),\n",
       "    (1923, 1929, 'Skills'),\n",
       "    (1868, 1871, 'Skills'),\n",
       "    (1579, 1582, 'Skills'),\n",
       "    (1562, 1569, 'Skills'),\n",
       "    (1205, 1208, 'Skills'),\n",
       "    (1087, 1096, 'Experience'),\n",
       "    (573, 580, 'Location')]}),\n",
       " (\"Job description\\nMerchandising data science team at Walmart Labs is focused on using the latest research in machine learning, statistics and optimization to solve business problems in assortment, pricing and replenishment areas. We build prescriptive models to empower decision-making, work with engineers to build reference architectures and machine learning pipelines in a big data ecosystem. Bespoke machine learning algorithms researched and developed by our team will help Walmart to optimize merchandising operations, business practices and change the way our customers shop.\\nThe data science community at Walmart Labs is active in most of the Hack events, utilizing the petabytes of data at our disposal, to build some of the coolest ideas. All the work we do at Walmart Labs benefits our operations & our associates, helping Customers Save Money to Live Better.\\nYour Opportunity\\nAs a Staff Data Scientist for Walmart Labs, youï¿½ll have the opportunity to\\nApply and/or develop statistical modeling techniques (such as deep nueral networks and Bayesian models), optimization methods and other ML techniques.\\nDevelop efficient and scalable models at Walmart scale.\\nCollaborate with counterparts in business, engineering and science to find impactful solutions to business problems.\\nDefine and/or own the model goodness metrics and track the business impact over time.\\nPresent recommendations from complex analysis to business partners in clear and actionable form, influencing the future plans.\\nYour Responsibility\\nManage the continuous improvement of data science and machine learning by following industry best practices and staying up-to-date with and extending the state-of-the-art in Machine Learning Research.\\nIntegrate data science solutions into current business processes.\\nDevelop and recommend process standards and best practices in Machine Learning as applicable to the retail industry.\\nMentor peers and junior members and handle multiple projects at the same time.\\nConsult with business stakeholders across stores and ecommerce businesses regarding algorithm-based recommendations and be a thought-leader to develop these into business actions.\\nEngage and partner with universities, institutes and vendor partners to bring in ideas and innovation into the labs environment.\\nPeer review and publish work in top tier ML/AI conferences such as NIPS, ICML, AAAI and COLT\\nParticipate and speak at various external forums such as research conferences and technical summits.\\nPromote and support company policies, procedures, mission, values, and standards of ethics and integrity\\nBachelor's with > 10 years of relevant experience OR Masters with > 8 years of relevant experience OR PhD in Computer Science with > 6 years of relevant experience.\\nExperience in analyzing complex problems and translating them to data science algorithms with due attention to computational efficiency and testing at scale.\\nExpertise in machine learning, supervised and unsupervised: Forecasting, Classification, Data/Text Mining, NLP, Decision Trees, Adaptive Decision Algorithms, Random Forest, Search Algorithms, Neural Networks, Deep Learning Algorithms and Reinforecement Learning\\nExperience in statistical learning: Predictive & Prescriptive Analytics, Web Analytics, Parametric and Non-parametric models, Regression, Time Series, Dynamic / Causal Model, Statistical Learning, Guided Decisions, Topic Modeling\\nExperience working with big data - identifying trends, patterns, and outliers in large volumes of data.\\nExperience in leading Junior Data Scientists on approach and results.\\nExperience with Python and one Object Oriented Programming Language.\\nWorked with at least one main stream machine learning framework such as caffe, convNet, Tensor Flow and Torch\\nExperience with SQL, relational databases and data warehouse\\nExperience with big data platforms - Hadoop(Hive, Pig, Map Reduce, HQL) / Spark / H20\\nDomain Knowledge : Merchandising Divisions in Retail.\\nGuidewire InsurancePlatform is the P&C industry platform that unifies software, services, and partner ecosystem to power our customersï¿½ business. InsurancePlatform provides the standard upon which insurers can engage their customers, optimize their operations, drive smart decisions, and innovate quickly. We are privileged to serve more than 350 P&C insurers in 32 countries. We invest heavily in R&D to build a technology platform that combines three elementsï¿½core processing, data and analytics, and digital engagementï¿½to enhance insurersï¿½ ability to engage and empower their customers and employees.\\nGuidewireï¿½s Cyence Risk Analytics products help the property & casualty (P&C) industry to model new and evolving risks such as cyber. By combining internet-scale data listening, adaptive machine learning, and insurance risk modeling, Cyence Risk Analytics provides insights that help P&C customers face new risks, take advantage of new opportunities, and develop new products. To learn more about Cyence Risk Analytics, please visit https://www.guidewire.com/products/cyence. shhameed@guidewire.com\\n9.\",\n",
       "  {'entities': [(4749, 4765, 'Skills'),\n",
       "    (3854, 3861, 'Skills'),\n",
       "    (3834, 3841, 'Skills'),\n",
       "    (3773, 3776, 'Skills'),\n",
       "    (3751, 3756, 'Skills'),\n",
       "    (3735, 3746, 'Skills'),\n",
       "    (3684, 3700, 'Skills'),\n",
       "    (3428, 3435, 'Skills'),\n",
       "    (3188, 3208, 'Skills'),\n",
       "    (2925, 2941, 'Skills'),\n",
       "    (2722, 2729, 'Experience'),\n",
       "    (2691, 2694, 'Qualification'),\n",
       "    (2657, 2664, 'Experience'),\n",
       "    (2642, 2649, 'Qualification'),\n",
       "    (2607, 2615, 'Experience'),\n",
       "    (2589, 2597, 'Qualification'),\n",
       "    (1572, 1588, 'Skills'),\n",
       "    (402, 418, 'Skills'),\n",
       "    (374, 381, 'Skills'),\n",
       "    (342, 358, 'Skills'),\n",
       "    (107, 123, 'Skills')]}),\n",
       " ('Position Title - Senior Data Scientist (Marketing Analytics)\\nJob Purpose\\nThe purpose of this role is to bring in the culture of Data aggregation and analysis, from recognizing human patterns in the numbers, to improving the consumer experience via analytics, to finding ways to bring data to achieve organizations Goals & objective\\nKey Responsibilities\\nBe responsible for scaling our analytics capability across all internal disciplines and guide our strategic direction in regards to analytics\\nTranslating business needs to technical requirements and implementation\\nOrganize and analyze large, diverse data sets across multiple platforms\\nIdentify key insights and leverage them to inform and influence product strategy\\nProactively developing new analyses and insights, to drive decisions and strategies for marketing (customer lifetime modeling, user acquisition, retention, monetization, etc.) and game design\\nBuilding both always-on decision engines and one-off analyses\\nWorking with all parts of the business to identify analytical requirements and formalize an approach for reliable, relevant, accurate, efficient solutions for those requirements\\nDesigning and implementing advanced machine learning algorithms\\nDeliver concise verbal and written explanations of analyses to senior management that elevate findings into strategic recommendations\\nJob Requirements\\nQualifications\\nEngineering / Statistics graduate\\nExperience\\n4+ years experience in analytics\\nKnowledge of analytics, machine learning\\nStrong Python / R expertise\\nProven track record of designing and building integrations between 3rd party Ad-Tech platforms.\\nDeep understanding of the Ad-Tech ecosystem, particularly RTB, SSP, ad serving, ad exchange and header bidding technologies\\nReal time high volume systems\\nIdentifying KPIï¿½s (Key Performance Indicator) in collaboration with other function(Product, Marketing, Engineering etc)\\nA/B testing to achieve the KPIï¿½s\\nDriving traffic to website, apps\\nUnderstanding conversion rate optimization (CRO) principles and hacks and being able to apply CRO hacks to any businesses\\nPrioritizing growth channels\\nScaling and Automating the growth processes\\nKnowledgeable about referral marketing and being able to create viral growth\\nStartup experience',\n",
       "  {'entities': [(1882, 1893, 'Qualification'),\n",
       "    (1517, 1528, 'Skills'),\n",
       "    (1508, 1514, 'Skills'),\n",
       "    (1484, 1500, 'Skills'),\n",
       "    (1473, 1482, 'Skills'),\n",
       "    (1450, 1459, 'Skills'),\n",
       "    (1427, 1436, 'Experience'),\n",
       "    (1396, 1415, 'Qualification'),\n",
       "    (1382, 1393, 'Qualification'),\n",
       "    (1188, 1204, 'Skills'),\n",
       "    (485, 494, 'Skills'),\n",
       "    (384, 393, 'Skills'),\n",
       "    (248, 257, 'Skills')]}),\n",
       " ('10.\\nJob description\\nJoin ABB and work in a team that is dedicated to creating a future where innovative digital technologies allow greater access to cleaner energy.\\nABB is a global technology leader in industrial digitalization. ABB operates in more than 100 countries with about 147,000 employees and $34 billion revenue.\\nIn India, ABB has been operating for over a century. At present, we have 40 factories at 9 locations that develop best-in-class products bringing together global expertise, with local experience. India is also home to ABB groupï¿½s largest engineering design and R&D center, where our engineers work on cutting-edge technologies to develop the future offerings from engineering tools to analytics solutions.\\nIndustrial Automation Division provides modern solutions for various types of industries. The division consists of eight business units Oil, Gas and Chemicals (IAOG), Process Industries (IAPI), Power Generation (IAPG). Marine and Ports (IAMP), Turbocharging (IATU), Control Technologies (IACT), Measurement and Analytics (IAMA) and Machine & Factory Automation (IAMF). There are 1800+ employees in IA division.\\nAs a Statistical Modeling - Data Scientist you will be part of Industrial Automation - Digital Organization and will be based in Mumbai / Bengaluru.\\nTo help the worldï¿½s most asset-intensive industries solve their biggest challenges, we are looking for a experts Data Science for developing enterprise solutions for on-premise and cloud platforms like Azure / AWS.\\nTasks\\nDevelop Machine Learning and Artificial Intelligence based solutions for our Industrial Automation Digital Organization team. In this role the candidate will be in a key position to utilize the latest developments in industrial digitalization, connected devices and systems.\\nDevelop Machine Learning and Artificial Intelligence based solutions for our Industrial Automation Digital Organization team.\\nCreate scalable models and algorithms for integrating into proprietary tools and products.\\nAnalyze the data, understanding of characteristics, evaluate alternate models, validate hypothesis through theoretical and empirical approaches.\\nCreate statistical and predictive models for equipment monitoring, failure detection, life estimation and life extension.\\nBuild tools and support structures needed for analyzing data, perform data cleansing, feature selection and feature engineering and organizing experiments in conjunction with best practices.\\nCreate and deliver proof of solutions utilizing latest technology and tools\\nUnderstand various data structures and apply methods to clean and transform the data.\\nDesigning and developing statistical models and applications fitting to business requirement.\\nStudy and transform data science prototypes.\\nPerform data mining, pattern recognition, statistical analysis using large structure and unstructured data including time-series, device data, image, documents etc.\\nPerform statistical analysis and fine-tuning using test results.\\nLiving ABBï¿½s core values of safety and integrity, which means taking responsibility for your own actions while caring for your colleagues and the business.\\nRequirements\\nProven experience as a Machine Learning, Statistics, Deep Learning, Recommendation system (Prescriptive analytics), Neural Networks and NLP.\\nStrong understanding of statistical modeling and its applications to solve business requirements.\\nConceptual understanding of various modeling techniques and Pros & Cons for the approaches.\\nHands on experience with R, Python, Java, Tensorflow and Big data machine learning platforms.\\nUnderstanding of data structures, data modeling and software architecture.\\nKnowledge of math, probability, statistics and algorithms.\\nOutstanding analytical and problem-solving skills.\\nKnowledge of Python, R or Java languages and machine learning libraries.\\nUnderstanding of tools such as Tensorflow, Matlab, Big Data Machine learning libraries .\\nExperience in developing solutions for Energy and process industries would be preferable.\\nKnowledge of data science tools, techniques and its software engineering lifecycle.\\nStrong communication and collaboration skills\\nBachelors / Masters degree from a reputed university.\\nShould have an experience of 3 - 8 years in relevant field.',\n",
       "  {'entities': [(4235, 4246, 'Experience'),\n",
       "    (4164, 4171, 'Qualification'),\n",
       "    (4152, 4161, 'Qualification'),\n",
       "    (3874, 3884, 'Skills'),\n",
       "    (3815, 3831, 'Skills'),\n",
       "    (3796, 3800, 'Skills'),\n",
       "    (3782, 3789, 'Skills'),\n",
       "    (3557, 3573, 'Skills'),\n",
       "    (3548, 3556, 'Skills'),\n",
       "    (3533, 3543, 'Skills'),\n",
       "    (3527, 3531, 'Skills'),\n",
       "    (3518, 3525, 'Skills'),\n",
       "    (3296, 3299, 'Skills'),\n",
       "    (3276, 3291, 'Skills'),\n",
       "    (1278, 1287, 'Location'),\n",
       "    (1269, 1275, 'Location')]}),\n",
       " ('11.\\nJob description\\nJob Description\\nJob Profile:\\nData Scientist to build delivery of Digital Workplace Support Services - Software Licensing & Management Solutions (SLMS)\\nArchitect and Developer of Data Analytics solution to integrate products for SLMS\\nUnderstand the DXC go-forward strategies for SLMS\\nEngage regularly with offerings from DXC Partners for SLMS\\nCreate Data Models for Data Analysis around software usage, and how to present those in Dashboards .\\nDesired Candidate\\nTotal Experience ï¿½ 3-5 Years\\nExperience with Data Modeling: Understanding data from different sources, and modeling, transforming the data\\nExperience with tools that can be used for data visualization such as: Tableau, Microsoft BI, Domo\\nWorking on early stage Data analysis and conceptualizing data models and trial data-sets for analysis\\nInvestigation of multiple data visualization tools and technologies and hands-on testing, comparisons of data outputs\\nHands-on implementation of Data Modeling and Visualization\\nExcellent communicator (both verbal and written), strong analytical ability .\\nGood To Have\\nCloud service providers for SLMS ï¿½ Amazon AWS, Microsoft Azure\\nUnderstanding of software volume license agreements',\n",
       "  {'entities': [(1136, 1151, 'Skills'),\n",
       "    (1124, 1134, 'Skills'),\n",
       "    (966, 979, 'Skills'),\n",
       "    (700, 712, 'Skills'),\n",
       "    (691, 698, 'Skills'),\n",
       "    (526, 539, 'Skills'),\n",
       "    (499, 509, 'Experience')]}),\n",
       " (\"12.\\nJob description\\nDescription\\nConduent is the world's largest provider of diversified business process services with leading capabilities in transaction processing, automation, analytics and constituent experience. We work with both government and commercial customers in assisting them to deliver quality services to the people they serve.\\nWe manage interactions with patients and the insured for a significant portion of the U.S. healthcare industry. We are the customer interface for large segments of the technology industry and the operational and processing partner of choice for public transportation systems around the world.\\nWhether it's digital payments, claims processing, benefit administration, automated tolling, customer care or distributed learning - Conduent manages and modernizes these interactions to create value for both our clients and their constituents. Learn more at www.conduent.com.\\nWe are looking for data scientists to work on machine learning, data mining, and statistical modeling for predictive and prescriptive enterprise analytics. Successful candidates will be expected to investigate state of the art techniques in advanced machine learning and statistical modeling, and design, develop, and deploy state-of-art, scalable systems for innovative analytics applications in a set of industrial verticals (e.g. healthcare, transportation, customer care etc.). Applicants will be expected to work with a diverse set of data sources, such as time series data, spatial, graph data, semi-structured and unstructured data, and build statistical/machine-learning models in support of on-demand, real-time analytic services. The applicant should also have strong skills in explaining and interpreting the analytic models and outcomes in both research and application contexts.\\nResponsibilities\\nResearch, design and prototype robust and scalable models based on machine learning, data mining, and statistical modeling to answer key business problems\\nBuild tools and support structures needed to analyze data, perform elements of data cleaning, feature selection and feature engineering and organize experiments in conjunction with best practices\\nWork with development teams & business groups to ensure models can be implemented as part of a delivered solution replicable across many clients\\nPresent findings to stakeholders to drive improvements and solutions from concept through to delivery\\nKeep abreast of the latest developments in the field by continuous learning and proactively champion promising new methods relevant to the problems at hand\\nCollaborate closely with university partners and other scientists and engineers in a multidisciplinary work environment\\nQualifications\\nPhD in computer science, computer engineering or MS with 5+ years of experience in related field.\\nDemonstrated history of driving and delivering analytics models and solutions\\nDeep knowledge of fundamentals of machine learning, data mining and statistical predictive modeling, and extensive experience applying these methods to real world problems\\nStrong skills in software prototyping and engineering with expertise in applicable programming and analytics languages (Python, R, C/C++) and various open source machine learning and analytics packages to generate deliverable modules and prototype demonstrations of their work\\nDesired interdisciplinary skills include big data technologies, ETL, statistics and causal inference, Deep Learning, modeling and simulation\\nBreadth of skills and experience in machine learning ï¿½ diverse types of data, diverse data sources, different types of learning models, diverse learning settings\\nAbility and inclination to work in multi-disciplinary environments, and desire to see ideas realized in practice\\nExperience and knowledge in services domains such as business process outsourcing systems, transportation systems, healthcare systems and financial services is valued\\n13.\",\n",
       "  {'entities': [(3190, 3195, 'Skills'),\n",
       "    (3179, 3185, 'Skills'),\n",
       "    (2768, 2776, 'Experience'),\n",
       "    (2711, 2714, 'Qualification')]}),\n",
       " (\"As a part of this, we need experienced individuals focusing on research and development of methods for processing huge amount of content.\\nWhat You Get To Do In This Role\\nDevelop algorithms that utilize deep learning and traditional methods in NLP and computer vision\\nCreate experiments, algorithms and prototypes that not only yield high-accuracy but are also designed and engineered to scale.\\nCollaborate across multiple research and engineering disciplines, making the tradeoffs required to rapidly deliver software solutions\\nIn order to be successful in this role, we need someone who has:\\n8+ overall industry experience with atleast 4+ years in applying AI/ML principles to real world applications.\\nBroad NLP knowledge: tokenisation, part-of-speech tagging, dependency parsing, syntactic parsing, word sense disambiguation, topic modeling; contextual text mining, Word embedding\\nBroad Computer Vision knowledge:\\nConstruction, Feature detection, Segmentation, Classification\\nobject detection, tracking, localisation, classification, recognition, scene understanding\\nFace detection / alignment / recognition /tracking /attribute recognition/expression analysis.\\nVideo stabilization/ denoising / super-resolution / stitching / enhancement\\nBroad Machine Learning experience - Algorithm Evaluation, Preparation, Analysis, Modeling and Execution\\nExposure to Deep Learning - CNNs, LSTMs, network architecture, network tuning, transfer learning, multi-task learning\\nExperience in using Tensorflow, Caffe and/or other neural network development frameworks.\\nExposure to Open source NLP libraries e.g. NLTK, Regex, Stanford NLP, OpenNLP/CoreNLP\\nExposure to AWS/Azure/GPU is a plus\\nAt Adobe, you will be immersed in an exceptional work environment that is recognized throughout the world on Best Companies lists. You will also be surrounded by colleagues who are committed to helping each other grow through our unique Check-In approach where ongoing feedback flows freely.\\nIf youï¿½re looking to make an impact, Adobe's the place for you. Discover what our employees are saying about their career experiences on the Adobe Life blog and explore the meaningful benefits we offer.\\nAdobe is an equal opportunity employer. We welcome and encourage diversity in the workplace regardless of race, gender, religion, age, sexual orientation, gender identity, disability or veteran status.\\nDemonstrated ability to propose novel solutions to problems, performing experiments to show feasibility of their solutions and working to refine the solutions into a real-world context\\nStrong analytical, written, and verbal communication skills\",\n",
       "  {'entities': [(1654, 1659, 'Skills'),\n",
       "    (1649, 1653, 'Skills'),\n",
       "    (1594, 1599, 'Skills'),\n",
       "    (637, 645, 'Experience'),\n",
       "    (593, 595, 'Experience'),\n",
       "    (202, 215, 'Skills')]}),\n",
       " (\"14.\\nJob description\\nJob Description\\nYou and IBM India\\nIBM's Purpose is to be essential to our clients, to the world and one another and we are confident that together as IBMers we will drive this purpose. Joining IBM is about joining a culture of openness, teamwork, trust, and the invitation and expectation to have a voice. Join us and Do your Best Work Ever.\\nIBM is recognized gold standard for inclusion, reflected in winning, to name few, the 2018 Catalyst Award for advancing women in business, the National Award Best Employer of People with Disabilities and being named one of the top 5 2018 Top Companies for Women Technologists for building an inclusive workplace ï¿½ We advocate for fairness and equality as everyone is, and always has been, welcome at IBM.\\nBusiness Unit Introduction\\nWe at IBM Global Business Services (GBS) are a dynamic group of Business, Strategy and Technology professionals - a specific source of market-leading Industry Consulting, Application and Business process management, supported by the industry's most sophisticated outcome-based delivery model. All designed to be the Digital Reinvention partner for leading clients across the world - providing value-led and asset-powered end to end solutions.\\nWith a global footprint in over 170 countries, we are empowering clients to build upon their tremendous heritage in Application Innovation processes and also transform them to a Cloud, Cognitive and Social centric world. With skills across six sectors and 17 industries, all major service lines and competencies, IBMï¿½s GBS is a promising business unit in itself to be a part of.\\nThrough our unique global delivery network; IBM offers global expertise coupled with a deep understanding of local capabilities, markets and cultures you could be part of and partner on some great projects with some of the best corporations in the world across geographies.\\nOur IBM and Salesforce strategic partnerships strengthens and delivers new solutions to enterprise customers using IBM Cloud and Watson services with Salesforce Quip and Salesforce Service Cloud Einstein. Together we deliver solutions that bring together the power of AI and enable companies to make smarter decisions, faster than ever before.\\nWho You Are\\nAs Data Scientist, you will develop, maintain, evaluate and test big data solutions. You will be involved in the design of data solutions using Artificial Intelligence based technologies like H2O, Tensorflow.\\nSkills in designing algorithms, implementing pipelines, validating model performance, and developing interfaces such as APIs. Expertise in working with IBM Watson services using Python Also experience with Spark, Hadoop, SQL (HANA)\\nWhat You Will Do\\nYou are responsible for designing algorithms and implementation including loading from disparate data sets, pre-processing using Hive and Pig.\\nScope and deliver solutions with the ability to design solutions independently based on high-level architecture.\\nMaintain the production systems like Kafka, Hadoop, Cassandra, Elasticsearch\\nHow weï¿½ll help you grow: \\nYouï¿½ll have access to all the technical and management training courses that will help you\\nYouï¿½ll learn directly from guide developers in the field; our team leads love to mentor\\nYou have the opportunity to work in many different areas to identify what really excites you\\nRequired Technical and Professional Expertise\\nMinimum 5+ years of experience in IT Industry\\nTechnology expertise of solutioning in Hadoop, Hive, Spark / PySpark, SQL, Oozie along Data Modelling in Hive\\nExperience in programming Languages- Java / Python / Scala and ability to demonstrate micro / macro designing and familiar with Unix Commands and basic work experience in Unix Shell Scripting\\nWorking knowledge in one NoSQL database like MongoDB/Cassandra/HBase/Couchbase\\nHands-on experience of various Big data architectures like Lambda / kappa with usage of automation / scheduling tool like Oozie or Cronacle or any other technology\\nProven ability in solutioning covering data ingestion, data cleansing, ETL, data mart creation and exposing data for consumers\\nPreferred Tech And Prof Experience\\nHands-on 2 yearsï¿½ experience in real time Big Data projects is preferred\\nWorking knowledge with one cluster manager like Cloudera Manager or Ambari\\nAmbitious individual who can work under their own direction towards agreed targets/goals.\\nAbility to manage change and be open to it good time management and an ability to work under stress\\nProven interpersonal skills while contributing to team effort by accomplishing related results as needed\\nMaintain technical knowledge by attending educational workshops, reviewing publications\\n15.\",\n",
       "  {'entities': [(4143, 4150, 'Experience'),\n",
       "    (3774, 3781, 'Skills'),\n",
       "    (3754, 3759, 'Skills'),\n",
       "    (3590, 3595, 'Skills'),\n",
       "    (3532, 3536, 'Skills'),\n",
       "    (3490, 3495, 'Skills'),\n",
       "    (3488, 3495, 'Skills'),\n",
       "    (3480, 3485, 'Skills'),\n",
       "    (3474, 3478, 'Skills'),\n",
       "    (3465, 3472, 'Skills'),\n",
       "    (3389, 3397, 'Experience'),\n",
       "    (3003, 3010, 'Skills'),\n",
       "    (2833, 2837, 'Skills'),\n",
       "    (2667, 2674, 'Skills'),\n",
       "    (2661, 2666, 'Skills')]}),\n",
       " (\"Job description\\nThe Position Title will be based in Chennai Global Business Services Center.\\nWe are looking for someone who demonstrates\\nIntense collaboration\\nPassionate customer focus\\nThoughtful, fast, disciplined execution\\nTenacious commitment to continuous improvement\\nRelentless drive to win\\nHere is a glimpse of what youï¿½ll do\\nThe role is response for all business data analysis. Candidate will derive insights, provide recommendations that shape future strategies and guide current tactics by being a key partner to the organization in communicating findings and transforming them into strategies\\nThe role needs also to take the lead or collaborate with IT, Finance, Operations, Engineering, Pricing, Supply Chain and Sales teams for strategic initiatives and drive the team to achieve goals\\nThe role will have the opportunity to pursue exploratory analyses that shape long-term strategies as well as develop data-driven predictive tools for the use by the organization. Candidate will apply extensive data interpretation and analytical experience to drive insights, including training others. In addition, Candidate will need to use interpersonal and relationship skills to present insights to stakeholders and executives in a clear and compelling way\\nIdentify, structure and prioritize the problems\\nLeverage problem solving skills and frameworks to develop solutions to Materials Demand and Supply business problems\\nWork closely with development teams to ensure accurate integration of machine learning models into existing systems\\nStrong background in Python, SQL, and R.\\nDevelop advanced analytic models that relate Inventory and Demand\\nCollect data and facts from all kinds of sources and conduct the analysis\\nSynthesize and communicate findings to functional leaders and the management\\nGain immediate responsibility for project deliverables\\nHelp train colleagues on advanced techniques and tools\\nHere Is Some Of What Youï¿½ll Need (required)\\nBachelor's or master's degree in any discipline; strong academic performance with analytic and quantitative coursework is required: Information Technology, Statistics, Mathematics, Operations Research etc.; MBA degree is preferable\\n4+ years of relevant experience in the AA Projects and Overall 8 + Years of Industry Experience ( IT / Supply Chain)\\nProficiency in the Microsoft Office Suite & SQL\\nHere Are a Few Of Our Preferred Experiences\\nWork experience in Data Analytics, Business Analytics, or System Analytics is required\\nExperience in BAAN/SAP/Oracle ERP, CRM are preferred, but not required\\nHigh self-motivation, high standard of work ethic, maturity and personal initiative; Empathy, adaptability and emotional intelligence\\nStrong oral and written English and excellent communication skills\\nClose attention to detail, with a quality-focused mindset\\nSelf-discipline for planning and organizing tasks; demonstrated project-management leadership\\nDemonstrated problem-solving methodology\\nBe comfortable working with cross-functional teams and stakeholders, should demonstrate a strong driving force, and possess strong communication and persuasion skills\\nUnderstand, agree with and align with the organizationï¿½s values and leadership traits\\nDemonstrated strategic and creative thinking ability with a willingness to share and explore new ideas\\nA strong sense of responsibility, ownership and pride in delivering quality results and understanding the business impact\\nConsistent self-learning capabilities and adaptability to changes\\nFlex does not accept unsolicited resumes from headhunters, recruitment agencies or fee based recruitment services. Flex is an Equal Opportunity Employer and employment selection decisions are based on merit, qualifications, and abilities. Flex pays for all costs associated with the application, interview or offer process, a candidate will not be asked for any payment related to these costs. Flex does not discriminate in employment opportunities or practices based on: age, race, religion, color, sex, national origin, marital status, sexual orientation, gender identity, veteran status, disability, pregnancy status or any other status protected by law. Flex provides reasonable accommodation so that qualified applicants with a disability may participate in the selection process. Please advise us of any accommodations you request to express interest in a position by e-mailing: accesibility@flextronics.com. Please state your request for assistance in your message. Only reasonable accommodation requests related to applying for a specific position within Flex will be reviewed at the e-mail address. Flex will contact you if it is determined that your background is a match to the required skills required for this position. Thank you for considering a career with Flex.\\nThe Information We Collect\\nWe may collect personal information that you choose to submit to us through the Website or otherwise provide to us. This may include your contact details; information provided in online questionnaires, feedback forms, or applications for employment; and information you provide such as CV/Resume. Your details will be provided to the entity you are applying for a job with. We will use your information for legitimate business purposes such as responding to comments or queries or answering questions; progressing applications for employment; allowing you to choose to share web content with others or; where you represent one of our customers or suppliers, administering the business relationship with that customer or supplier. We will process your data in accordance with our recruitment privacy notice.\\nIf you have any queries about the processing of your data, please contact:\",\n",
       "  {'entities': [(2345, 2348, 'Skills'),\n",
       "    (2246, 2256, 'Experience'),\n",
       "    (2184, 2192, 'Experience'),\n",
       "    (1966, 1972, 'Qualification'),\n",
       "    (1952, 1960, 'Qualification'),\n",
       "    (1569, 1572, 'Skills'),\n",
       "    (1561, 1567, 'Skills'),\n",
       "    (370, 383, 'Skills'),\n",
       "    (52, 59, 'Location')]}),\n",
       " (\"15.\\nJob description\\nAbout The Team\\nThe Marketing Operations Reporting and Data Science team manage the reporting and analytical analysis aspects of Akamai's marketing organizations. These include such activities as reporting and analyzing key performance metrics, developing segmentation and product propensity approaches, and determine value of marketing activities and potential of deal conversion through marketing actions to drive efficiency gains and optimize resource utilization. The Reporting and Data Science team in Marketing Operations is responsible for business performance metrics, attribution metrics, and predictive models that drive our marketing initiatives.\\nAbout The Job\\nAkamai is growing fast, and so is the volume of data we manage. We need someone with the experience to apply sophisticated data analysis techniques in our fast-changing, entrepreneurial environment. If you love being the detective, analyzing business problems, predicting the future, eliminating the status quo, and testing whether your hypotheses were right, then this role is full of opportunity for you.\\nThis scientist will work closely with Marketing, Sales, Finance, and IT analyzing hierarchical data, predicting and optimizing sales, and determining the best marketing and sales plays and when to launch those plays. A successful scientist in this role will know how to connect and leverage existing, but disparate, data inside and outside of Akamai. An outstanding scientist will see what they are missing, creating and testing out new solutions ï¿½ including getting your hands dirty, and cleaning data to reveal patterns.\\nIf you enjoy taking a business problem and turning it into actionable output into a system for others to act on and use, then youï¿½ll like this job. This really isnï¿½t a job for the faint of heart ï¿½ you must be persistent ï¿½ you must be someone that never surrenders and never retreats; someone with a ï¿½relentless forward motionï¿½Thrilled by small victories, undeterred by setbacksï¿½ until finally reaching your goal.\\nResponsibilities\\nHandle adhoc and unscheduled data science support requests from Sales and Marketing to clarify and further business insight\\n* Review and operationalize existing production models to improve performance, scalability, and resource utilization\\n* Scope, create, deliver, and implement data transformations to support team initiatives\\n* Use critical thinking skills to define and validate ambiguous business objectives and concepts such as addressable market size, customer lifetime value, or predictive lift\\n* Communicate technical concepts across diverse organizations\\n* Help business leaders in Sales and Marketing formulate critical questions that may be answered through analytics\\n* Take initiative to keep up with developments in the field of data science, and to independently learn on the job.\\nBasic Qualifications\\nBS/BA with 5 yearsï¿½ experience, or MBA/MA with 3+ yearsï¿½ experience in business, finance, or statistics, with hands-on experience conducting statistical analyses, including developing and implementing predictive models\\n3+ yearsï¿½ experience with SQL, Linux (PostgreSQL, Oracle, SQL Server), R (R Studio and command line) feature engineering, dimensionality reduction, linear and non-linear regression; experience manipulating and cleaning data\\n3+ yearsï¿½ experience in evaluating and implementing new data sources and analytical solutions\\n2+ yearsï¿½ experience working in a sales or marketing functional team\\n2+ yearsï¿½ experience working with sales and marketing performance data, and solid understanding of marketing and marketing KPIs\\n2+ yearsï¿½ experience with extracting and parsing unstructured data (e.g., XML, JSON).\\n1+ yearsï¿½ experience communicating and presenting insights from complex data to non-technical audiences\\n1+ yearsï¿½ experience and success in working with cross-functional teams (especially IT, sales, services, marketing, finance, and customer support)\\nDesired Qualifications\\nProficiency in R Studio Server, R, SQL, Tableau, ETL, Python\\nExperience with Spark, Hadoop, and related Big Data technologies\\nExperience creating and deploying production statistical and machine learning models\\n16.\",\n",
       "  {'entities': [(4047, 4053, 'Skills'),\n",
       "    (4040, 4045, 'Skills'),\n",
       "    (4017, 4023, 'Skills'),\n",
       "    (4003, 4010, 'Skills'),\n",
       "    (3998, 4001, 'Skills'),\n",
       "    (3978, 3993, 'Skills'),\n",
       "    (3793, 3802, 'Experience'),\n",
       "    (3793, 3801, 'Experience'),\n",
       "    (3689, 3698, 'Experience'),\n",
       "    (3689, 3697, 'Experience'),\n",
       "    (3603, 3612, 'Experience'),\n",
       "    (3603, 3611, 'Experience'),\n",
       "    (3475, 3484, 'Experience'),\n",
       "    (3475, 3483, 'Experience'),\n",
       "    (3406, 3415, 'Experience'),\n",
       "    (3406, 3414, 'Experience'),\n",
       "    (3312, 3321, 'Experience'),\n",
       "    (3312, 3320, 'Experience'),\n",
       "    (3146, 3149, 'Skills'),\n",
       "    (3133, 3136, 'Skills'),\n",
       "    (3114, 3117, 'Skills'),\n",
       "    (3088, 3097, 'Experience'),\n",
       "    (3088, 3096, 'Experience'),\n",
       "    (2916, 2925, 'Experience'),\n",
       "    (2916, 2924, 'Experience'),\n",
       "    (2903, 2910, 'Qualification'),\n",
       "    (2880, 2888, 'Experience'),\n",
       "    (2880, 2887, 'Experience'),\n",
       "    (2869, 2875, 'Qualification')]}),\n",
       " (\"Job description\\nJPMorgan Chase is a leading global financial services firm with assets of over $1.1 trillion and operations in more than 50 countries. The firm is a leader in Investment Banking, Financial Services for consumers and businesses, financial transaction processing, asset and wealth management, and private equity. Under the JPMorgan and Chase brands, the firm serves millions of consumers in the United States and many of the world's most prominent corporate, institutional and government clients. Further information about J.P. Morgan is available at http://www.jpmorgan.com/.\\nThe role is for a Machine Learning Engineer ï¿½ Lead within the Corporate Machine Learning Engineering and Services function for corporate functions across JPMorgan Chase, including Global Finance, Corporate Treasury, Risk Management, Human Resources, Compliance, Legal, and all functions within the Corporate Administrative Office (CAO). The ML Engineering and Services team will create services and platforms that will provide re-usable components and an end-to-end development to deployment environment to accelerate time-to-market for data science teams.\\nThe ML Engineer - Lead in Bangalore will be part of a globally distributed team, with data science and engineering partners in New York and EMEA. He/she will lead a team of engineers to productionize robust and scalable ML models, and enable the services to be deployed and integrated into existing business workflow. He/she will also build common ML capabilities used across Corporate based on those models. These capabilities will be delivered in an agile way, on internal open source code base, in a test driven manner. This is an exciting opportunity to work on cutting-edge solutions and have a profound influence on the business processes of a leading global bank.\\nResponsibilities\\nBuild common ML capabilities used across Corporate based on machine learning models\\nLead development of one or more of:\\nNext-generation big data based machine learning frameworks and back-end services\\nFront-end web applications and back-end services that integrate with other products.\\nHigh-performance processing and analytics applications using Spark\\nRobust analytic data pipelines\\nAutomate and streamline existing processes, procedures, and toolsets\\nInnovate new ways of managing, transforming and validating data\\nEnsure code paths are unit tested, defect free and integration tested\\nMentor and coach junior team members to build a high-performing team\\nQualifications/ Technical Skills\\nBA/BS degree or equivalent experience in Computer Science, Information Technology or related disciplines\\n10+ years of exceptional hands-on knowledge of robust software design and development\\nStrong Java/ Python programming skills and Web Services (spring boot)\\nExperience in Big Data technologies and utilities (Hadoop, Spark SQL, Hive, Impala, Pig, Kafka)\\nExpertise in distributed computing and micro services\\nExposure to or interest in ML\\nExpertise in designing and implementing scalable solutions in the analytics space\\nExperience in building reliable and auditable CICD deployment pipeline using Jenkins\\nExposure working with Cloud based applications\\nProven proficiency with data and variety of databases\\nExposure/competence with Agile Development approach\\nAbility to collaborate with high-performing teams and individuals throughout the firm to accomplish common goals\\nFinancial Services background or experience preferred.\\nExperience in developing visualizations in Tableau, R, or other BI platforms\\nExperience in creating APIs using R and deploying models in Marketo and Salesforce\\nExperience in the high-tech industry\\nIndependent and critical thinker\\nAbility to work directly with diverse people of different backgrounds\\nStrong problem-solving skills when faced with disparate data sets\\nStrong oral communication skills and ability to present analytical results to non-technical audience\\n17.\",\n",
       "  {'entities': [(3497, 3504, 'Skills'),\n",
       "    (3259, 3285, 'Skills'),\n",
       "    (3155, 3179, 'Skills'),\n",
       "    (2875, 2880, 'Skills'),\n",
       "    (2869, 2873, 'Skills'),\n",
       "    (2862, 2868, 'Skills'),\n",
       "    (2855, 2860, 'Skills'),\n",
       "    (2851, 2854, 'Skills'),\n",
       "    (2837, 2843, 'Skills'),\n",
       "    (2729, 2735, 'Skills'),\n",
       "    (2723, 2727, 'Skills'),\n",
       "    (2630, 2639, 'Experience'),\n",
       "    (2530, 2537, 'Qualification'),\n",
       "    (1987, 2003, 'Skills'),\n",
       "    (1896, 1912, 'Skills'),\n",
       "    (1275, 1283, 'Location'),\n",
       "    (1174, 1183, 'Location')]}),\n",
       " (\"Job description\\nThoughtWorks India is looking for talented Data scientists passionate about building large scale Machine Learning Solutions to help manage the ever-growing information needs of our clients.\\nEducation : MS or equivalent in Applied mathematics, statistics, physics, computer science or operations research background is a MUST. Minimum of 8 years of total experience and 5+ years as Data Scientist in real-time projects\\nSkills\\nPassion for understanding business problems and trying to address them by leveraging data - characterized by high-volume, high dimensionality from multiple sources\\nAbility to communicate complex models and analysis in a clear and precise manner\\nExperience with building predictive statistical, behavioral or other models via supervised and unsupervised machine learning, statistical analysis, and other predictive modeling techniques.\\nExperience using R, Python or equivalent statistical/data analysis tools. Ability to transfer that knowledge to different tools\\nExperience with matrices, distributions and probability\\nProficiency with relational databases and NoSQL\\nExperience in Machine Learning, Deep Learning solution,, Neural Networks and Natural language processing.\\nExperience with Map/Reduce, Hadoop, Hive etc. is a plus\\nExperience in consulting skills\\nResponsibilities\\nHas worked in a big data environment before alongside a big data engineering team (and data visualization team, data and business analysts)\\nTranslate client's business requirements into a set of analytical models\\nPerform data analysis (with a representative sample data slice) and build/prototype the model(s)\\nWork with the client's business users and/or data scientists to define and close on the model design\\nProvide inputs to the data ingestion/engineering team on input data required by the model, size, format, associations, cleansing required\\nIdentify/Provide approach and data to validate the model(s)\\nCollaborate with a technology/data engineering team to transfer the business understanding, get the model productionized and validate the output along with business users\\nTune the model(s) to improve results provided over time\\nUnderstand business challenges and goals of a client to formulate the approach for data analysis and model creation that will support their business decision making\\nDo hands-on data analysis and model creation and proactively mentor other team members\\nWork in highly collaborative teams that strive to build quality systems and provide business value\\nWork closely with clients, both in the Business Domain and with Technical staff members\\nHave the opportunity to work in a number of different domains in a variety of different client environments\\nTravel to work at client sites and other ThoughtWorks offices. This may include international travel\\nContinually learn, mentor and develop your career\",\n",
       "  {'entities': [(1250, 1254, 'Skills'),\n",
       "    (1242, 1248, 'Skills'),\n",
       "    (1230, 1240, 'Skills'),\n",
       "    (1165, 1181, 'Skills'),\n",
       "    (1140, 1154, 'Skills'),\n",
       "    (1122, 1138, 'Skills'),\n",
       "    (896, 902, 'Skills'),\n",
       "    (385, 393, 'Experience'),\n",
       "    (353, 360, 'Experience'),\n",
       "    (218, 220, 'Qualification'),\n",
       "    (113, 129, 'Skills')]}),\n",
       " ('18.\\nJob description\\nWhat the role entails\\nResearch, implement and deploy advanced statistical models (machine learning, deep learning, time series models)\\nLead the Data Science team as technical lead, delivery lead and mentor\\nBuild personal networks within the company based on trust, passion for making a difference and positive attitude\\nDrive understanding and adoption of Data Science process and programs in the company.\\nThought leadership to formulate business problem into meaningful analytical problems, modifying approach based on deeper understanding of business process\\nMature approach to evaluating model efficacy\\nWork closely with Data Management and MIS teams to deploy full stack analytics solutions\\nWhat we are looking for in you\\nDeep technical understanding in the field of Advanced Statistical Modelling, Machine Learning, Deep Learning, Time Series Modelling and related technologies.\\nDeep experience developing AI models in real-world environments and deploying AI/ML into production applications.\\nPassion for creating meaningful impact, with ability to direct technical development with a focus on adoption and process change.\\nDemonstrate and communicate a high level of ownership and commitment to achieving results\\nTalent for communicating technical results to business stakeholders, convincingly conveying the impact and drivers of the results.\\nExperience & Education\\n8+ years experience in Data Science/Quantitative modelling\\nProficiency with data mining, mathematics, and statistical analysis\\nAdvanced pattern recognition and predictive modeling experience\\nAdvanced programming skills in R/Python\\nThorough understanding of Hadoop ecosystem\\nComfort working in a dynamic, research-oriented group with several ongoing concurrent projects\\nMasterï¿½s or PHD degree in stats, applied math, or related discipline\\nAnalytics product delivery experience\\n19.',\n",
       "  {'entities': [(1772, 1775, 'Qualification'),\n",
       "    (1760, 1766, 'Qualification'),\n",
       "    (1613, 1621, 'Skills'),\n",
       "    (1414, 1426, 'Skills'),\n",
       "    (1391, 1399, 'Experience'),\n",
       "    (980, 986, 'Skills'),\n",
       "    (375, 387, 'Skills'),\n",
       "    (164, 176, 'Skills'),\n",
       "    (120, 133, 'Skills'),\n",
       "    (102, 118, 'Skills')]}),\n",
       " (\"Job description\\nAbout Data Sciences At Flipkart\\nThe Data Sciences team at Flipkart is on a mission to build systemic intelligence across Flipkart products and the overarching ecosystem. Being Indiaï¿½s largest online\\nmarketplace and the most used e-commerce app in India, places Flipkart in a unique position and gives this team a distinctive opportunity ï¿½ to decipher the richest\\npossible data about Indian consumers. Add the dimension of a vast product selection and a proliferating seller base to that and what you get is a multitude of disruptive\\npossibilities.\\nIn a nutshell, the terabytes of daily data compounded in Flipkartï¿½s data centers offer a dynamic mix of numerical, structured, unstructured, image- and audio-based statistics, all set to define shopping in the future.\\nWhat This Job Entails\\nThe pool of data available at Flipkart forms the foundation to solve some present and predictable challenges for shoppers in India. As a Data Scientist you will be working on:\\nProduct discovery along with personalization and intent modeling\\nDemand shaping and planning\\nHeterogeneous networks for consumer, product and seller interactions\\nCustomer insights\\nCatalog enhancement and product insights\\nCustomer emotion detection and right response matching\\nFulfillment automation\\nOptimization of last mile delivery\\nFraud modeling\\nAssociations And Collaborations\\nThe Flipkart Data Science team is also leveraging partnerships with Indian and foreign universities ï¿½ like CMU, IIT's, IISc and IIITï¿½s ï¿½ for developing class-leading solutions in the e-commerce sector.\\nAt Flipkart, the work of a Data Scientist involves collaboration with the engineering and product teams to ensure a holistic outcome at the product delivery. The flat functional structure within Flipkart engineering enables data scientists to focus on excellence and create a deep sense of ownership at every stage of work.\\nWorking@Flipkart:\\nData Sciences techniques at Flipkart span classification, clustering, matrix factorization,graphical models, networks and graph algorithms, topic modeling, image processing,deep learning and NLP ï¿½ each one of them being applied across large scale initiatives.\\nIf you aspire to redefine ï¿½state-of-the-artï¿½ and create an impact on Indiaï¿½s shopping landscape, Flipkart Data Science Organization offers the podium to solve challenging real-world problems and take a giant leap in your career as a Data Scientist.\\nQualifications And Experience\\nB.Tech/M.Tech/PhD in CS/Statistics with demonstrable experience through publications/deployed solutions/projects. Experience of over 8 years.\\n20.\",\n",
       "  {'entities': [(2577, 2584, 'Experience'),\n",
       "    (2458, 2461, 'Qualification'),\n",
       "    (2451, 2457, 'Qualification'),\n",
       "    (2444, 2450, 'Qualification'),\n",
       "    (2270, 2283, 'Skills'),\n",
       "    (2234, 2239, 'Location'),\n",
       "    (2096, 2099, 'Skills'),\n",
       "    (2078, 2091, 'Skills'),\n",
       "    (2061, 2077, 'Skills'),\n",
       "    (1429, 1434, 'Location'),\n",
       "    (1373, 1386, 'Skills'),\n",
       "    (929, 934, 'Location'),\n",
       "    (399, 404, 'Location'),\n",
       "    (263, 268, 'Location'),\n",
       "    (192, 197, 'Location'),\n",
       "    (51, 64, 'Skills'),\n",
       "    (21, 34, 'Skills')]}),\n",
       " ('Job description\\nShort Description:\\nAs a data scientist, youï¿½d be working towards developing cutting edge products and solutions that are based on state of the art machine learning algorithms. You will be joining the 247sï¿½ core R&D team, which is based in Bangalore. The core R&D team works on real-world challenging problems in the web-analytics domain.\\nSome of the attractive pluses of the job are:\\nThe opportunity to work with a world class team of talented data scientists with strong background in machine learning, and who are extremely passionate about solving real-world applied problems in the web-analytics domain.\\nA real opportunity to expand your skill-sets and a chance to learn and use the latest advances and approaches in machine learning and data mining on real world datasets\\nA big plus is the opportunity to play and work with what are really ï¿½big-dataï¿½ datasets.\\nWorking in a university like work-environment where you are expected to be self-motivated and are measured on your performance.\\nDetailed Description:\\nIn this role, you will be required to have the following skills:\\nIntermediate to advanced knowledge of machine learning, probability theory, statistics and algorithms. You will be required to discuss and use various algorithms and approaches on a daily basis.\\nExtremely strong programming skills: Since most of the core R&D teamsï¿½ work involves solving problems in the big-data domain, preparing datasets for algorithmic exploration is a significant part of the job. You should have strong programming skills (preferably in python), in order to play around with the raw data, and also for deploying various algorithms\\nStrong analytical skills: We seek individuals who try to look at a problem from various angles, and who have deep analytical skills to understand, grasp and discuss deeply technical and significantly complicated problems, and the solutions that the R&D team is working on.\\nMinimum Requirements (Educational Qualification & Work Experience)\\nCandidates from a reputable institution like IITs, IISc, or equivalent\\n1-4 years of work experience in machine learning and data mining domain, where you have been actively involved in industry research. We will be willing to talk to exceptionally qualified freshers too.\\nCompetency Requirements:\\nYou should be self-motivated to solve interesting research problems that have a huge business and revenue potential. The core R&D team works in a university like environment, where you are encouraged to become self-reliant and be passionate about the problems that you are working on.\\nStrong communication skills are needed. You should be able to explain and discuss deeply technical stuff on a day to day basis. The ability to understand others, as well as having the communication skills to discuss science on a daily basis is an absolute requirement.',\n",
       "  {'entities': [(2093, 2109, 'Skills'),\n",
       "    (2061, 2070, 'Experience'),\n",
       "    (1556, 1562, 'Skills'),\n",
       "    (1402, 1409, 'Skills'),\n",
       "    (1401, 1409, 'Skills'),\n",
       "    (1135, 1151, 'Skills'),\n",
       "    (862, 870, 'Skills'),\n",
       "    (737, 753, 'Skills'),\n",
       "    (502, 518, 'Skills'),\n",
       "    (255, 264, 'Location'),\n",
       "    (163, 179, 'Skills')]}),\n",
       " ('22.\\nJob Requisition:\\nSr Data Scientist\\nPrimary Location:\\nBangalore\\nJob Description:\\nThe Data Scientist will work on challenging problems extracting actionable information out of the many data sources available to Neustar, particularly geospatial data. They will assist in developing accurate and precise models of user behavior based on this geospatial data using various analytical tools, including data curation, data visualization, supervised, and unsupervised machine learning. The data sets under analysis are large, and growing larger still, and so the data scientist must be proficient in the design and development of CPU and memory efficient algorithms.\\nApplication areas include Identity Resolution, Marketing Analytics Security and Fraud and other Business Solutions supported by our or our clientï¿½s data.\\nData Scientists create prototypes of new algorithms and support Engineering teams in productizing these capabilities. Data Scientists work closely with various teams including data acquisition, data products, data sciences and various business units including marketing, security, and internet of things to ensure implementation of capabilities that enable the organizationï¿½s vision. The role is based out of India at the Neustar offices in Bangalore.\\nResponsibilities:\\nGroup Leadership: Mentoring and supporting the career and capability growth of her/his team members. Setting and monitoring project schedules, communicating progress to the larger team. Provide technical leadership and foster a climate of open creative collaboration with his/her team and with other colleagues.\\nAlgorithm Development: Develop a deep understanding of all the data relevant to the problem to be addressed. Establish deterministic and probabilistic linkages between data sources and develop ways to extract and summarize the sought information in the data using a wide variety of statistical, data mining and machine learning techniques.\\nPrototyping: Create prototypes of productizable ways to perform the analysis at scale, provide documentation and help educate your colleagues in different function about the solution\\nSupport Implementation: Closely work with product, engineering and client teams to incorporate Data Science capabilities into Neustarï¿½s products and services\\nExperience and Qualifications:\\nMastersï¿½s degree in Data Science, Statistics or a related field (we will consider applicants with a Bachelorï¿½s degree and relevant work experience as well)\\nAt least three years of experience working on data-intensive analytics solutions & more than 5 years of overall experience.\\nSolid understanding of data mining and statistics concepts and familiarity with real-world applications of these techniques.\\nHands on experience in Machine Learning\\nHands on experience in Machine Learning\\nExperience on Geospatial data is preferred.\\nSolid knowledge of SQL in its various forms for traditional databases and distributed computing environments\\nExperience working with commercial and/or open source statistics and data mining packages\\nExperience working on large distributed datasets using Hive SQL, Spark, Python\\nStrong written and oral communication skills\\nStrong inter-personal collaboration skills. Being able to both work in groups or as an individual contributor\\nGeneral curiosity, a willingness to experiment, pragmatism and the ability to handle ambiguity',\n",
       "  {'entities': [(3137, 3162, 'Skills'),\n",
       "    (3099, 3102, 'Skills'),\n",
       "    (3018, 3029, 'Skills'),\n",
       "    (2859, 2862, 'Skills'),\n",
       "    (2779, 2795, 'Skills'),\n",
       "    (2739, 2755, 'Skills'),\n",
       "    (2614, 2625, 'Skills'),\n",
       "    (2560, 2568, 'Experience'),\n",
       "    (2311, 2318, 'Qualification'),\n",
       "    (1909, 1926, 'Skills'),\n",
       "    (1894, 1905, 'Skills'),\n",
       "    (1258, 1267, 'Location'),\n",
       "    (463, 480, 'Skills'),\n",
       "    (415, 433, 'Skills'),\n",
       "    (57, 66, 'Location')]}),\n",
       " (\"21.\\nJob description\\nRole:  Data Scientist.\\nLocation: Bangalore, Chennai, Pune \\nExp:  5 to 15 years\\nData scientist with a strong background in data mining, machine learning, recommendation systems, big data, and statistics. Should possess signature strengths of a qualified mathematician with the ability to apply concepts of Mathematics, Applied Statistics and Data mining to produce insights through effective visualization, exploratory analyses, and inferential statistics. A strong data engineering background with hands-on technology capabilities is a MUST to own and deliver outcomes.\\nA Bachelor or Masterï¿½s Degree in a highly quantitative field (Computer Science, Machine Learning, Operational Research, Statistics, Mathematics, etc.) or equivalent experience, 7+ years of industry experience in predictive modelling, data science and analysis, with prior experience in a ML or data scientist role and a track record of building ML or DL models.\\nResponsibilities and skills:\\nWork with our customers to deliver an ML / DL project from beginning to end, including understanding the business need, aggregating data, exploring data, building & validating predictive models, and deploying completed models to deliver business impact to the organization.\\nSelecting features, building and optimizing classifiers using ML techniques\\nData mining using state-of-the-art methods, create text mining pipelines to clean & process large unstructured datasets to reveal high-quality information and hidden insights using machine learning techniques\\nShould be able to appreciate and work on Computer Vision problems ï¿½ for example, extract rich information from images to categorize and process visual dataï¿½ Develop machine learning algorithms for object and image classification, Experience in using DBScan, PCA, Random Forests and Multinomial Logistic Regression to select the best features to classify objects.\\nExcellent understanding of machine learning techniques and algorithms, such as k-NN, Naive Bayes, SVM, Decision Forests, etc. Needs to appreciate deep learning frameworks like MXNet, Caffe 2, Keras, Tensorflow\\nExperience working with GPUs to develop models, handling terabyte size datasets\\nExperience with common data science toolkits, such as R, Weka, NumPy, MatLab, mlr, mllib, Scikit-learn, caret etc - excellence in at least one of these is highly desirable\\nShould be able to work hands-on in Python, R etc. Should closely collaborate & work with engineering teams to iteratively analyze data using Scala, Spark, Hadoop, Kafka, Storm etc.,\\nExperience with NoSQL databases and familiarity with data visualization tools will be of great advantage \\nCompensation\\nWe offer competitive salary, health benefits, facilities like cab, gym etc. You'll be joining a bunch of geeks who love to innovate.\",\n",
       "  {'entities': [(2563, 2578, 'Skills'),\n",
       "    (2408, 2409, 'Skills'),\n",
       "    (2263, 2269, 'Skills'),\n",
       "    (2256, 2261, 'Skills'),\n",
       "    (2250, 2254, 'Skills'),\n",
       "    (2247, 2248, 'Skills'),\n",
       "    (2102, 2112, 'Skills'),\n",
       "    (2095, 2100, 'Skills'),\n",
       "    (1843, 1844, 'Skills'),\n",
       "    (1803, 1817, 'Skills'),\n",
       "    (1803, 1804, 'Skills'),\n",
       "    (1798, 1801, 'Skills'),\n",
       "    (1790, 1796, 'Skills'),\n",
       "    (1317, 1330, 'Skills'),\n",
       "    (952, 953, 'Skills'),\n",
       "    (766, 776, 'Experience'),\n",
       "    (700, 701, 'Skills'),\n",
       "    (590, 619, 'Qualification'),\n",
       "    (85, 98, 'Experience'),\n",
       "    (73, 77, 'Location'),\n",
       "    (64, 71, 'Location'),\n",
       "    (53, 62, 'Location'),\n",
       "    (20, 21, 'Skills')]}),\n",
       " (\"23.\\nJob description\\nDescription\\nData Scientist is a role to build world class Data Science/ business intelligence, analytics, and reporting systems for LMT teams.\\nAmazon's Last Mile Data Science team is looking for a Data Scientist to optimize one of the most complex logistics systems in the world. Academic and/or practical background in Computer Science, Engineering, Operations Research, or Process Control are particularly relevant for this position. Experience in the integration of model-based engineering tools and/or multidisciplinary analysis & optimization is also a plus.\\nAmazonï¿½s extensive logistics system comprises thousands of fixed infrastructure nodes with millions of possible connections between them. Billions of packages flow through this network on a yearly basis, making the impact of optimal improvements truly unparalleled. This magnificent challenge is a terrific opportunity to understand, model, simulate, optimize, and reshape one of the world's most complex systems.\\nYour main focus will be come up with efficient model-based optimization tools, at various levels of fidelity, used in designing our transportation network. You will make the real complexity of our logistics system visible, tangible, and manageable using cutting edge algorithmic methods. You will integrate modeling and simulation capabilities to validate assumptions on the intricate interactions among different elements of our system. You will identify and evaluate opportunities to improve customer experience, network speed, cost, and the efficiency of capital investment. You will improve the capability of systems analyses that use optimization, simulation, and machine learning techniques. You will quantify the improvements resulting from the application of these tools and you will evaluate trade-offs between competing outputs of the system.\\nThis position requires drive and self-motivation, superior analytical thinking, data-driven disposition, application of technical knowledge to a business context, effective collaboration with fellow Data scientists, software development engineers, and product managers, effective communication of technical designs to technical and non-technical audiences, and close partnership with many stakeholders from operations, finance, IT, and business leadership.\\nBasic Qualifications\\nPhD / Masters /Bachelor Degree in Data Science, Analytics, Computer Science Engg., Systems Engg., Statistics\\n5+ years of experience with relevant technologies, enterprise reporting systems, data analytics.\\n5+ years of experience in working as an analytics or data engineering member working with cross functional teams.\\nPreferred Qualifications\\nMaster Degree in Data Science, Analytics, Computer Science Engg., Systems Engg., Statistics with 3+ years of relevant experience\\nExperience working with enterprise reporting systems, data analytics.\\nExperience working as an Analytics Engineer or Data Scientist working with cross functional teams.\\nExperience working with data visualization tools and creating data visualization concepts. (Excel, Tableau, or similar)\\nExperience of statistical analysis and tools such as Python, R, or equivalent.\\nFamiliarity with AWS RedShift and other distributed computing technologies preferred.\\nWS RedShift And Other Distributed Computing Technologies Preferred.\",\n",
       "  {'entities': [(3257, 3268, 'Skills'),\n",
       "    (3189, 3200, 'Skills'),\n",
       "    (3188, 3200, 'Skills'),\n",
       "    (3145, 3151, 'Skills'),\n",
       "    (3071, 3078, 'Skills'),\n",
       "    (3064, 3069, 'Skills'),\n",
       "    (3034, 3052, 'Skills'),\n",
       "    (2996, 3014, 'Skills'),\n",
       "    (2857, 2871, 'Skills'),\n",
       "    (2771, 2779, 'Experience'),\n",
       "    (2691, 2703, 'Skills'),\n",
       "    (2674, 2687, 'Qualification'),\n",
       "    (2535, 2543, 'Experience'),\n",
       "    (2519, 2533, 'Skills'),\n",
       "    (2438, 2446, 'Experience'),\n",
       "    (2363, 2375, 'Skills'),\n",
       "    (2329, 2359, 'Qualification'),\n",
       "    (1667, 1683, 'Skills'),\n",
       "    (182, 194, 'Skills'),\n",
       "    (78, 90, 'Skills')]}),\n",
       " ('24.\\nmfineï¿½s approach is to aggregate primary care demand onto a digital platform and create a hyper local care delivery network of providers. Branded clinics/hospitals, particularly the mid-sized ones, view this as the ï¿½Cloud Clinicï¿½ they are looking for and missing today.\\nUniqueness of mfine:\\nThere are 4 fundamentally differentiated capabilities of mfine platform\\nIts hospital lead and not individual doctor lead - so , better, maturity of processes, quality, and brand trust\\nRemote diagnosis and treatment with data : devices, and home vitals and sample collection\\nScalable with care team concept. 24x7 care team for case prep, case follow up and all front-ending with the consumer\\nIncreased Doctor Productivity with use of AI driven apps/tools for the doctors - both the Sr.Consultants and as well as care team doctors.\\nAbout Founders:\\nPrasad and Ashutosh are technology entrepreneurs and have built and run large businesses and teams. Ashutosh was the Co-founder of Myntra and was pretty much involved in every part of the business through the last 10 years. Prasad was the Chief Business Officer of Myntra and was instrumental in shaping Myntraï¿½s strategy and growth over the last 4-5 years. Both are technologists and led Myntra through industry shaping moves, be it building a premium consumer brand, leading the way in m-commerce or creating growth with technology and consumer experience. They grew passionate about consumer internet opportunities in India as they built Myntra to be a billion dollar online fashion platform from ground up.\\nmfine is the venture they started after moving on from Myntra in Jan 2017. They have put together a very strong initial team that brings with it technology, business and healthcare experience/expertise.\\n[Platform] mfineï¿½s platform manifests into a consumer app and a care team app (for doctors and care team). The apps are powered with AI/BOTs that enrich the interaction between the consumers and doctors, make the clinic workflows efficient and deliver a proactive care experience for the users with personalized information/notifications. The App is the go to place for all data for the consumers and providers - be it historical records or real time streaming from connected health devices. At the backend of the apps is the integration with provider network that enables smooth admin & operations between mfine and each provider.\\nCompany Details:\\nIndustry: Healthcare\\nCompany Incorporation: Feb 2017\\nNo of Employees: 130\\nGeography: Bangalore\\nFounders:\\nPrasad Kompalli (CEO & Co-founder) : https://www.linkedin.com/in/prasadkompalli/\\nAshutosh Lawania (Co-founder) : https://www.linkedin.com/in/lawania/\\nAjit Narayanan (CTO) : https://www.linkedin.com/in/ajitnarayanan/\\nJD of Data Scientist (NLP) \\nHere are some areas where based on your choice & experience you would be working on:\\nBe the AI champion in the team, own the AI modelï¿½s success from concept level to production deployment and successful optimization\\nBuild/Enhance NLP/ML models for various components within our NLP stack (see our current stack)\\nScaling/Optimizing AI models for various verticals, languages, and clients\\nBring in a greater degree of reinforcement learning capability to all AI components in the platform\\nStay current with the latest research in AI space, relevant to our platform, and lead the effort to experiment/apply them to help constantly improve the platform\\n25.',\n",
       "  {'entities': [(3084, 3092, 'Skills'),\n",
       "    (2982, 2989, 'Skills'),\n",
       "    (2878, 2886, 'Skills'),\n",
       "    (2489, 2498, 'Location'),\n",
       "    (1188, 1197, 'Experience')]}),\n",
       " ('Job description\\nExperience required ï¿½ 4- 7 years\\nQualification - Graduates from Premium Institutes\\nResponsibilities -\\nIdentify use cases in the sports domain, especially cricket\\nCollaborate with various teams ï¿½ tech, product, business, data warehousing, etc. to make sure there is an organizational alignment in solving the data science goals for business\\nTest hypothesis with data and validate\\nAnalyze data and bring the output in a consumable form for the stakeholders\\nWork hands-on on various analytics problems and provide thought leadership on problems that we are working on\\nMap the results to KPIs and track the performance of the model and communicate the findings to the stakeholders ï¿½ track the whole problem journey and understand how models have improved the existing problem\\nRequired Skills:\\nMin. 2-3  year of database experience with advanced SQL skills)\\nUnderstanding of the sports domain, especially cricket, to identify use cases where analytics can play a major role\\nGathering knowledge about the background of data and various data sources, preparing datasets specific to the use case\\nExperience working with complex analytical tools, such as SAS or R\\nExperience with data visualization tools, such as Tableau/Spot fire/Qlikview\\nKnows MS Excel & PowerPoint\\nAbility to communicate insights with a sound business understanding avoiding the technical details\\nStrong understanding with data infrastructure, data warehouse, or data engineering\\nSKILLS / EXPERIENCE\\nExperience level of 5 to 8 years as Data Scientist\\nï¿½       Proven experience of working on NLP problems and working knowledge of various tools/frameworks used for building solutions in NLP space\\nï¿½       Must have experience of building NLP models from concept level, to production deployment and post-deployment optimizations\\nï¿½       Strong problem-solving skills, data structures, and algorithms\\nï¿½       Experience with distributed systems handling a large amount of data\\nï¿½       Excellent coding skills in any one/more among Python, R, Ruby\\nQUALIFICATIONS\\nB.Tech/BE /M. Tech/ Ph.D. in Computer Science or equivalent from a reputed college (Tier 1)\\n26.',\n",
       "  {'entities': [(2056, 2061, 'Qualification'),\n",
       "    (2047, 2054, 'Qualification'),\n",
       "    (2043, 2045, 'Qualification'),\n",
       "    (2036, 2042, 'Qualification'),\n",
       "    (2005, 2011, 'Skills'),\n",
       "    (1843, 1858, 'Skills'),\n",
       "    (1497, 1510, 'Experience'),\n",
       "    (1220, 1228, 'Skills'),\n",
       "    (1187, 1211, 'Skills'),\n",
       "    (810, 819, 'Experience'),\n",
       "    (38, 48, 'Experience')]}),\n",
       " ('ob description\\nExperience : 3 - 8 years\\nResponsibilities\\nSelecting features, building and optimizing classifiers using machine learning techniques\\nData mining using state-of-the-art methods\\nExtending companyï¿½s data with third party sources of information when needed\\nEnhancing data collection procedures to include information that is relevant for building analytic systems\\nProcessing, cleansing, and verifying the integrity of data used for analysis\\nDoing ad-hoc analysis and presenting results in a clear manner\\nCreating automated anomaly detection systems and constant tracking of its performance\\nSkills and Qualifications\\nExcellent understanding of machine learning techniques and algorithms, such as k-NN, Naive Bayes, SVM, Decision Forests, etc.\\nExperience with common data science toolkits, such as R, Weka, NumPy, MatLab, etc. Excellence in at least one of these is highly desirable\\nGreat communication skills\\nExperience with data visualisation tools, such as D3.js, GGplot, etc.\\nProficiency in using query languages such as SQL, Hive, Pig\\nExperience with NoSQL databases, such as MongoDB, Cassandra, HBase\\nGood applied statistics skills, such as distributions, statistical testing, regression, etc.\\nGood scripting and programming skills\\nFourKites, Inc. is a logistics technology startup providing a next-generation software platform that streamlines operations for freight brokers and shippers. Our connected devices platform is the most advanced in the industry and has been deployed by several freight brokerage houses in the country. Our customers include Fortune 100 shippers and Transport Topics Top 25 Freight Brokers. We love what we do, and we love the impact we have already driven for the clients we work with. We believe in empowering our employees to be the absolute best they can be, and we arenï¿½t afraid to have a little fun in the process. Weï¿½re funded by a great group of investors who care about our company and our teamï¿½s success.\\nSeniority Level\\nEntry level\\nIndustry\\nInformation Technology & Services Computer Software Internet\\nEmployment Type\\nFull-time\\nJob Functions\\nEngineering Information Technology',\n",
       "  {'entities': [(1109, 1114, 'Skills'),\n",
       "    (1098, 1107, 'Skills'),\n",
       "    (1089, 1096, 'Skills'),\n",
       "    (1066, 1069, 'Skills'),\n",
       "    (1044, 1047, 'Skills'),\n",
       "    (1038, 1042, 'Skills'),\n",
       "    (1033, 1036, 'Skills'),\n",
       "    (968, 973, 'Skills'),\n",
       "    (897, 917, 'Skills'),\n",
       "    (822, 828, 'Skills'),\n",
       "    (815, 820, 'Skills'),\n",
       "    (809, 813, 'Skills'),\n",
       "    (806, 807, 'Skills'),\n",
       "    (728, 745, 'Skills'),\n",
       "    (723, 727, 'Skills'),\n",
       "    (711, 722, 'Skills'),\n",
       "    (705, 709, 'Skills'),\n",
       "    (28, 39, 'Experience')]}),\n",
       " (\"30.\\nob description\\nResponsibilities For Data Scientist\\nWork with stakeholders throughout the organization to identify opportunities for leveraging company data to drive business solutions.\\nMine and analyze data from company databases to drive optimization and improvement of product development, marketing techniques and business strategies.\\nAssess the effectiveness and accuracy of new data sources and data gathering techniques.\\nDevelop custom data models and algorithms to apply to data sets.\\nUse predictive modeling to increase and optimize customer experiences, revenue generation, ad targeting and other business outcomes.\\nDevelop company A/B testing framework and test model quality.\\nCoordinate with different functional teams to implement models and monitor outcomes.\\nDevelop processes and tools to monitor and analyze model performance and data accuracy.\\nQualifications For Data Scientist\\nStrong problem solving skills with an emphasis on product development.\\nExperience using statistical computer languages (R, Python, SLQ, etc.) to manipulate data and draw insights from large data sets.\\nExperience working with and creating data architectures.\\nKnowledge of a variety of machine learning techniques (clustering, decision tree learning, artificial neural networks, etc.) and their real-world advantages/drawbacks.\\nKnowledge of advanced statistical techniques and concepts (regression, properties of distributions, statistical tests and proper usage, etc.) and experience with applications.\\nExcellent written and verbal communication skills for coordinating across teams.\\nA drive to learn and master new technologies and techniques.\\nWe're looking for someone with 8-10 years of experience manipulating data sets and building statistical models, has a Master's or PHD in Statistics, Mathematics, Computer Science or another quantitative field, and is familiar with the following software/tools :\\nCoding knowledge and experience with several languages: C, C++, Java, JavaScript, etc.\\nKnowledge and experience in statistical and data mining techniques: GLM/Regression, Random Forest, Boosting, Trees, text mining, social network analysis, etc.\\nExperience querying databases and using statistical computer languages: R, Python, SLQ, etc.\\nExperience using web services: Redshift, S3, Spark, DigitalOcean, etc.\\nExperience creating and using advanced machine learning algorithms and statistics: regression, simulation, scenario analysis, modeling, clustering, decision trees, neural networks, etc.\\nExperience analyzing data from 3rd party providers: Google Analytics, Site Catalyst, Coremetrics, Adwords, Crimson Hexagon, Facebook Insights, etc.\\nExperience with distributed data/computing tools: Map/Reduce, Hadoop, Hive, Spark, Gurobi, MySQL, etc.\\nExperience visualizing/presenting data for stakeholders using: Periscope, Business Objects, D3, ggplot, etc.\",\n",
       "  {'entities': [(2724, 2729, 'Skills'),\n",
       "    (2718, 2722, 'Skills'),\n",
       "    (2710, 2716, 'Skills'),\n",
       "    (2698, 2708, 'Skills'),\n",
       "    (2551, 2568, 'Skills'),\n",
       "    (2478, 2493, 'Skills'),\n",
       "    (2353, 2369, 'Skills'),\n",
       "    (2288, 2293, 'Skills'),\n",
       "    (2233, 2236, 'Skills'),\n",
       "    (2224, 2231, 'Skills'),\n",
       "    (2035, 2046, 'Skills'),\n",
       "    (1974, 1984, 'Skills'),\n",
       "    (1968, 1972, 'Skills'),\n",
       "    (1962, 1966, 'Skills'),\n",
       "    (1772, 1775, 'Qualification'),\n",
       "    (1760, 1766, 'Qualification'),\n",
       "    (1673, 1683, 'Experience'),\n",
       "    (1258, 1273, 'Skills'),\n",
       "    (1182, 1198, 'Skills'),\n",
       "    (1029, 1032, 'Skills'),\n",
       "    (1020, 1027, 'Skills')]}),\n",
       " (\"29.\\nJob description\\nGeneral Mills is reshaping the future of food. We believe food makes us better. It nourishes our bodies, brings us joy and connects us to each other. As one of the world's leading food companies, General Mills operates in more than 100 countries and markets more than 100 consumer brands, including Cheerios, Nature Valley, Betty Crocker, Yoplait, Annie's Homegrown, Old El Paso, Epic Provisions, Blue Buffalo and more. Are you passionate about the future of food? You've come to the right table. We want the very best talent to help lead something big.\\nGeneral Mills is seeking a Data Scientist to join a new data science team in the Global Business Solutions (shared services organization) that is tasked with collaborating with and enabling existing functional data science and analytics teams. This team also provides data science expertise and services to advance initiatives around demand forecasting, text classification, operational analytics, and machine learning to name just a few. It is also responsible for curating a community of practice to determine the best standards and practices around data science at General Mills\\nDevelop novel ways to help business partners achieve objectives through analysis & modelling\\nThink outside the box to identify & test new sources of information that unlock new business value\\nCurate and connect external data sets for broad enterprise-wide analytic usage\\nBe a storyteller to explain the ï¿½why & howï¿½ of your data driven recommendations to cross-functional teams\\nEngineer features by using your business acumen to bin, aggregate, pivot or encode data for optimal results\\nUtilize machine learning to create repeatable, dynamic & scalable models\\nHave passion to advocate and educate on the value and importance of data driven decision making & analytical methods\\nIdentify and develop long-term data science processes, frameworks, tools, and standards\\nBe a part of the team, collaborate, ask questions, engage and solicit feedback from other Data Scientists\\nConsultation, Collaborates with technical teams like development and infrastructure.\\nAble to explore, troubleshoot on niche technologies and provide automation solutions\\\\\\nExperienced in proposing ROI based solutions to business \\nQualification: Any Graduate (Preferred Statistical background)\\nExperience - 6+ yrs\\nStatistical analysis, modeling, clustering and data mining techniques to identify trends and insights\\nMathematical or statistical background required\\nAbility to incorporate a variety of data sources in an analysis (HDFS, file, database, JSON, HTML, etc)\\nUnderstanding of data warehousing & databases is critical\\nNumber sense, ability to identify questionable data, dig in & address it\\nExperience with Hadoop, Hive, and/or Spark a plus\\nBias for action with ability to deliver outstanding results through task prioritization & time management\\nExemplary organizational skills with attention to detail & accuracy\\nExperience with machine learning a plus\\nExperience with data visualization tools\\nExperience writing complex SQL queries\\nExperience with Python & R, comfortable working with DataFrames\\nStrong communication and collaboration skills to understand customer needs and deliver solutions in alignment with business needs\",\n",
       "  {'entities': [(3082, 3092, 'Skills'),\n",
       "    (3054, 3065, 'Skills'),\n",
       "    (2759, 2764, 'Skills'),\n",
       "    (2745, 2750, 'Skills'),\n",
       "    (2738, 2744, 'Skills'),\n",
       "    (2330, 2336, 'Experience'),\n",
       "    (2273, 2281, 'Qualification')]}),\n",
       " ('27.\\nJob description\\nTitle Data Scientist Desired Candidate Profile Masters in Economics Statistics Technology Up to 2 years of experience in applying analytics tools to support\\ndecision making Interest in working in development sectors Skills Competencies Strong analytical abilities Competency in working with qualitative and quantitative data Familiarity with tools and platforms for data value chain capture analysis presentation and dashboarding strongly preferred Good com\\nJob description\\nOur client, A global asset manager is looking for a Data Scientist to join their team in Mumbai.\\nShould have experience with application and development of machine learning algorithms. This is a brilliant opportunity to work directly with Portfolio Managers and Traders to discover opportunities in the market. Should be skilled in Python and/or C++, data analysis, modeling, back-testing, explore and analyze multidimensional data.\\nIf interested, email me at tanvikamdar@klicktosearch.com',\n",
       "  {'entities': [(860, 868, 'Skills'),\n",
       "    (845, 858, 'Skills'),\n",
       "    (840, 843, 'Skills'),\n",
       "    (826, 832, 'Skills'),\n",
       "    (649, 677, 'Skills'),\n",
       "    (583, 589, 'Location'),\n",
       "    (116, 123, 'Experience'),\n",
       "    (67, 98, 'Qualification')]})]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TRAIN_DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=None\n",
    "output_dir=Path(\"C:\\\\Users\\\\Anbu\\\\Desktop\\\\resp\")\n",
    "n_iter=50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created blank 'en' model\n"
     ]
    }
   ],
   "source": [
    "if model is not None:\n",
    "    nlp = spacy.load(model)  # load existing spaCy model\n",
    "    print(\"Loaded model '%s'\" % model)\n",
    "else:\n",
    "    nlp = spacy.blank(\"en\")  # create blank Language class\n",
    "    print(\"Created blank 'en' model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"ner\" not in nlp.pipe_names:\n",
    "    ner = nlp.create_pipe(\"ner\")\n",
    "    nlp.add_pipe(ner, last=True)\n",
    "    # otherwise, get it so we can add labels\n",
    "else:\n",
    "    ner = nlp.get_pipe(\"ner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ner': 228.2007167386661}\n",
      "{'ner': 218.80770673450945}\n",
      "{'ner': 201.46086339681884}\n",
      "{'ner': 157.57561630261657}\n",
      "{'ner': 134.32075051765773}\n",
      "{'ner': 200.70113242677076}\n",
      "{'ner': 131.81240396169187}\n",
      "{'ner': 160.04608435894107}\n",
      "{'ner': 134.70247963801089}\n",
      "{'ner': 85.33788671226743}\n",
      "{'ner': 118.55617733402748}\n",
      "{'ner': 98.00203176349319}\n",
      "{'ner': 83.15918017814528}\n",
      "{'ner': 105.1521067827413}\n",
      "{'ner': 71.51596529936255}\n",
      "{'ner': 55.97301921504784}\n",
      "{'ner': 71.81021871145404}\n",
      "{'ner': 69.19735871828495}\n",
      "{'ner': 68.83737079762832}\n",
      "{'ner': 62.99685307242146}\n",
      "{'ner': 65.02928421953052}\n",
      "{'ner': 36.81363454311117}\n",
      "{'ner': 61.18199341409871}\n",
      "{'ner': 62.57199275276579}\n",
      "{'ner': 43.41105791647907}\n",
      "{'ner': 32.993685412510864}\n",
      "{'ner': 37.97275124608687}\n",
      "{'ner': 58.22378561743055}\n",
      "{'ner': 27.3231391089834}\n",
      "{'ner': 39.75089669446113}\n",
      "{'ner': 48.91025416463335}\n",
      "{'ner': 24.414013535095265}\n",
      "{'ner': 16.54781921598597}\n",
      "{'ner': 37.40471476260107}\n",
      "{'ner': 34.923874100349934}\n",
      "{'ner': 33.22593534892605}\n",
      "{'ner': 26.019046114415325}\n",
      "{'ner': 15.41542665479175}\n",
      "{'ner': 40.4947896280945}\n",
      "{'ner': 35.44810019943733}\n",
      "{'ner': 20.468752910633743}\n",
      "{'ner': 26.82315821981085}\n",
      "{'ner': 28.222954730379506}\n",
      "{'ner': 20.916043021485297}\n",
      "{'ner': 23.9800669024005}\n",
      "{'ner': 14.654844242261326}\n",
      "{'ner': 20.59753914442211}\n",
      "{'ner': 18.874278110846987}\n",
      "{'ner': 17.311294945531383}\n",
      "{'ner': 19.44780343173407}\n"
     ]
    }
   ],
   "source": [
    "import tqdm\n",
    "nlp.vocab.vectors.name = 'spacy_trained_vectors'\n",
    "for _, annotations in TRAIN_DATA:\n",
    "    for ent in annotations.get(\"entities\"):\n",
    "        ner.add_label(ent[2])\n",
    "other_pipes = [pipe for pipe in nlp.pipe_names if pipe != 'ner']\n",
    "with nlp.disable_pipes(*other_pipes):  # only train NER\n",
    "    optimizer=nlp.begin_training()\n",
    "    for itn in range(n_iter):\n",
    "        random.shuffle(TRAIN_DATA)\n",
    "        losses = {}\n",
    "            # batch up the examples using spaCy's minibatch\n",
    "        batches = minibatch(TRAIN_DATA, size=compounding(4., 32., 1.001))\n",
    "        for text, annotations in (TRAIN_DATA):\n",
    "            nlp.update(\n",
    "                [text],\n",
    "                [annotations],\n",
    "                sgd=optimizer,\n",
    "                drop=0.35,\n",
    "                losses=losses\n",
    "                       )\n",
    "        print(losses)\n",
    "      \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to C:\\Users\\Anbu\\Desktop\\resp\n"
     ]
    }
   ],
   "source": [
    "    # save model to output directory\n",
    "if output_dir is not None:\n",
    "     output_dir = Path(output_dir)\n",
    "    if not output_dir.exists():\n",
    "        output_dir.mkdir()\n",
    "    nlp.to_disk(output_dir)\n",
    "    print(\"Saved model to\", output_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "wikitext=nlp(\" Reference Code- Inf_EXTERNAL_10038992_21Role Designation- Technology AnalystTechnical & Professional requirements- Basic Qualifications- - Experience Range- 3-5 years. At least 2 years of experience and excellent understanding of Machine learning techniques and algorithm such as Neural Networks, Naive Bayes, SVM, Decision Forests, etc.,o NLP, text analytics technologies.,o Common data science toolkits, such as R, Python Data Science Libraries, MatLab, etc. Excellence in at least one of these is highly desirable,o Data visualization tools, such as D3.js, GGplot, etc.,o Query languages such as SQL, Hive.,Good applied statistics skills, such as distributions, statistical testing, regression, etc.,At least 5 years of hands on experience with more than one programming language (Python / Scala/ Java/SQL),Role and responsibilities- - ,You will be responsible for delivering high-value next-generation products on aggressive deadlines and will be required to write high-quality, highly optimized/high-performance and maintainable code that your fellow developers love ,You will be a core member of a team that does whatever it takes to delight customers, take an iterative and result oriented approach to software development. In this position you will provide best-fit architectural solutions for multi-product, multi-project, multi-industry portfolios providing technology consultation and assisting in defining scope and sizing of work ,You will be the anchor in Proof of Concept developments and support opportunity identification and pursuit processes and evangelize Infosys brand ,You will collaborate with some of the best talent in the industry to create and implement innovative high quality solutions, lead and participate in sales and pursuits focused on our clients' business needs ,You will be part of a learning culture, where teamwork and collaboration are encouraged, excellence is rewarded, and diversity is respected and valued ,The role involves high end technology and hence would require you to be proficient in coding as well,Location- Bangalore Job Locations- Bangalore,BangaloreResponsibilites- Ensure effective Design, Development & Validation of activities in line with client needs and architectural requirements.,Ensure continual knowledge management.,Adherence to the organizational guidelines and processesSkills- R, Python, Machine Learning Company Description-Infosys is a leading provider of next generation consulting,technology and outsourcing solutions.We are dedicated to helping organizations,build tomorrows enterprise and advance the way the world works Thats why Forbes ranks us 19th among the top 100 most innovative companies. Our employees partner with clients to transform their business - one conversation; one idea; one insight at a time.While we are at it, some things remain unchanged- the unwavering ethics,transparency and respect behind everything we do. We will always be a company powered by intellect and driven by values.So, if your passion is to build solutions that  really make a difference to enterprises,the community and your world, Infosys is the right place for you.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp3=spacy.load(output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3-5 years Experience\n",
      "2 years Experience\n",
      "Machine learning Skills\n",
      "NLP Skills\n",
      "Python Skills\n",
      "Data Science Skills\n",
      "MatLab Skills\n",
      "Data visualization Skills\n",
      "5 years Experience\n",
      "Python Skills\n",
      "Scala/ Java Skills\n",
      "Bangalore Location\n",
      "Bangalore Location\n",
      "Python Skills\n",
      "Machine Learning Skills\n"
     ]
    }
   ],
   "source": [
    "for word in wikitext.ents:\n",
    "    print(word.text,word.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy import displacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"entities\" style=\"line-height: 2.5\"> Reference Code- Inf_EXTERNAL_10038992_21Role Designation- Technology AnalystTechnical & Professional requirements- Basic Qualifications- - Experience Range- \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    3-5 years\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">Experience</span>\n",
       "</mark>\n",
       ". At least \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    2 years\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">Experience</span>\n",
       "</mark>\n",
       " of experience and excellent understanding of \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    Machine learning\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">Skills</span>\n",
       "</mark>\n",
       " techniques and algorithm such as Neural Networks, Naive Bayes, SVM, Decision Forests, etc.,o \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    NLP\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">Skills</span>\n",
       "</mark>\n",
       ", text analytics technologies.,o Common data science toolkits, such as R, \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    Python\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">Skills</span>\n",
       "</mark>\n",
       " \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    Data Science\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">Skills</span>\n",
       "</mark>\n",
       " Libraries, \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    MatLab\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">Skills</span>\n",
       "</mark>\n",
       ", etc. Excellence in at least one of these is highly desirable,o \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    Data visualization\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">Skills</span>\n",
       "</mark>\n",
       " tools, such as D3.js, GGplot, etc.,o Query languages such as SQL, Hive.,Good applied statistics skills, such as distributions, statistical testing, regression, etc.,At least \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    5 years\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">Experience</span>\n",
       "</mark>\n",
       " of hands on experience with more than one programming language (\n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    Python\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">Skills</span>\n",
       "</mark>\n",
       " / \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    Scala/ Java\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">Skills</span>\n",
       "</mark>\n",
       "/SQL),Role and responsibilities- - ,You will be responsible for delivering high-value next-generation products on aggressive deadlines and will be required to write high-quality, highly optimized/high-performance and maintainable code that your fellow developers love ,You will be a core member of a team that does whatever it takes to delight customers, take an iterative and result oriented approach to software development. In this position you will provide best-fit architectural solutions for multi-product, multi-project, multi-industry portfolios providing technology consultation and assisting in defining scope and sizing of work ,You will be the anchor in Proof of Concept developments and support opportunity identification and pursuit processes and evangelize Infosys brand ,You will collaborate with some of the best talent in the industry to create and implement innovative high quality solutions, lead and participate in sales and pursuits focused on our clients' business needs ,You will be part of a learning culture, where teamwork and collaboration are encouraged, excellence is rewarded, and diversity is respected and valued ,The role involves high end technology and hence would require you to be proficient in coding as well,Location- \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    Bangalore\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">Location</span>\n",
       "</mark>\n",
       " Job Locations- \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    Bangalore\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">Location</span>\n",
       "</mark>\n",
       ",BangaloreResponsibilites- Ensure effective Design, Development & Validation of activities in line with client needs and architectural requirements.,Ensure continual knowledge management.,Adherence to the organizational guidelines and processesSkills- R, \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    Python\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">Skills</span>\n",
       "</mark>\n",
       ", \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    Machine Learning\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">Skills</span>\n",
       "</mark>\n",
       " Company Description-Infosys is a leading provider of next generation consulting,technology and outsourcing solutions.We are dedicated to helping organizations,build tomorrows enterprise and advance the way the world works Thats why Forbes ranks us 19th among the top 100 most innovative companies. Our employees partner with clients to transform their business - one conversation; one idea; one insight at a time.While we are at it, some things remain unchanged- the unwavering ethics,transparency and respect behind everything we do. We will always be a company powered by intellect and driven by values.So, if your passion is to build solutions that  really make a difference to enterprises,the community and your world, Infosys is the right place for you.</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "displacy.render(wikitext, style=\"ent\",jupyter=\"True\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Microsoft Sound Mapper - Input\n",
      "1 Microphone (Realtek High Defini\n",
      "2 Microsoft Sound Mapper - Output\n",
      "3 Speakers / Headphones (Realtek \n"
     ]
    }
   ],
   "source": [
    "import pyaudio\n",
    "p = pyaudio.PyAudio()\n",
    "for i in range(p.get_device_count()):\n",
    "    info = p.get_device_info_by_index(i)\n",
    "    print(info['index'], info['name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Say Something!\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-6c8d674747e8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0msr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMicrophone\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice_index\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msource\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mprint\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'Say Something!'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[0maudio\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlisten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msource\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m     \u001b[0mprint\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'Done!'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\speech_recognition\\__init__.py\u001b[0m in \u001b[0;36mlisten\u001b[1;34m(self, source, timeout, phrase_time_limit, snowboy_configuration)\u001b[0m\n\u001b[0;32m    650\u001b[0m                     \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    651\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 652\u001b[1;33m                 \u001b[0mbuffer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msource\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msource\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCHUNK\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    653\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;32mbreak\u001b[0m  \u001b[1;31m# reached end of the stream\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    654\u001b[0m                 \u001b[0mframes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\speech_recognition\\__init__.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, size)\u001b[0m\n\u001b[0;32m    159\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    160\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msize\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 161\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyaudio_stream\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexception_on_overflow\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    162\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    163\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pyaudio.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, num_frames, exception_on_overflow)\u001b[0m\n\u001b[0;32m    606\u001b[0m                           paCanNotReadFromAnOutputOnlyStream)\n\u001b[0;32m    607\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 608\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mpa\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_stream\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stream\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_frames\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexception_on_overflow\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    609\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    610\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_read_available\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import speech_recognition as sr\n",
    "\n",
    "r = sr.Recognizer()\n",
    "with sr.Microphone(device_index=1) as source:\n",
    "    print ('Say Something!')\n",
    "    audio = r.listen(source)\n",
    "    print ('Done!')\n",
    "    \n",
    "text = r.recognize_google(audio)\n",
    "print (text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speak Anything :\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-ce44ff323290>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0msr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMicrophone\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msource\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Speak Anything :\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[0maudio\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlisten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msource\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[0mtext\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecognize_google\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maudio\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\speech_recognition\\__init__.py\u001b[0m in \u001b[0;36mlisten\u001b[1;34m(self, source, timeout, phrase_time_limit, snowboy_configuration)\u001b[0m\n\u001b[0;32m    650\u001b[0m                     \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    651\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 652\u001b[1;33m                 \u001b[0mbuffer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msource\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msource\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCHUNK\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    653\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;32mbreak\u001b[0m  \u001b[1;31m# reached end of the stream\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    654\u001b[0m                 \u001b[0mframes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\speech_recognition\\__init__.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, size)\u001b[0m\n\u001b[0;32m    159\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    160\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msize\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 161\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyaudio_stream\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexception_on_overflow\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    162\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    163\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pyaudio.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, num_frames, exception_on_overflow)\u001b[0m\n\u001b[0;32m    606\u001b[0m                           paCanNotReadFromAnOutputOnlyStream)\n\u001b[0;32m    607\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 608\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mpa\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_stream\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stream\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_frames\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexception_on_overflow\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    609\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    610\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_read_available\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import speech_recognition as sr\n",
    "\n",
    "r = sr.Recognizer()\n",
    "with sr.Microphone() as source:\n",
    "    print(\"Speak Anything :\")\n",
    "    audio = r.listen(source)\n",
    "    try:\n",
    "        text = r.recognize_google(audio)\n",
    "        print(\"You said : {}\".format(text))\n",
    "    except:\n",
    "        print(\"Sorry could not recognize what you said\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
